{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-24T09:57:26.127538700Z",
     "start_time": "2025-12-24T09:49:09.195983Z"
    }
   },
   "source": [
    "# ============================================================\n",
    "# BOX 1/3 — Reading CSV snapshots + consistent crop + (re)gridding for FFT/FNO\n",
    "# ============================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "from flamekit.io_fields import field_path\n",
    "from flamekit.io_fronts import Case\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "# ----------------------------\n",
    "# USER SETTINGS\n",
    "# ----------------------------\n",
    "TIME_STEP_START = 200\n",
    "TIME_STEP_END   = 269\n",
    "\n",
    "PHI      = 0.40\n",
    "LAT_SIZE = \"025\"\n",
    "POST     = True\n",
    "\n",
    "BASE_DIR  = Path(\"../isocontours\")\n",
    "VAR_NAME  = \"T\"\n",
    "SORT_COLS = [\"x\", \"y\"]\n",
    "COORD_TOL = 0.0\n",
    "\n",
    "X_THESHOLD = 300  # keep only x > threshold (consistent)\n",
    "\n",
    "# FNO requires a uniform grid for FFT.\n",
    "# If your cropped points are not on a uniform tensor grid, we interpolate to a uniform grid.\n",
    "GRID_NX = 256\n",
    "GRID_NY = 128\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers (same style as your template)\n",
    "# ----------------------------\n",
    "def field_csv_path(base_dir: Path, phi: float, lat_size: str, time_step: int, post: bool) -> Path:\n",
    "    case = Case(\n",
    "        base_dir=base_dir,\n",
    "        phi=phi,\n",
    "        lat_size=lat_size,\n",
    "        time_step=time_step,\n",
    "        post=post,\n",
    "    )\n",
    "    return field_path(case)\n",
    "\n",
    "def read_field_sorted(path: Path, var_name: str, sort_cols: list[str]) -> tuple[np.ndarray, np.ndarray]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file:\\n  {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    missing = [c for c in (sort_cols + [var_name]) if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path.name}: missing columns {missing}\")\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=sort_cols + [var_name])\n",
    "    df = df.sort_values(sort_cols, kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    coords = df[sort_cols].to_numpy(dtype=np.float64)\n",
    "    values = df[var_name].to_numpy(dtype=np.float64)\n",
    "    return coords, values\n",
    "\n",
    "def coords_match(a: np.ndarray, b: np.ndarray, atol: float) -> bool:\n",
    "    if a.shape != b.shape:\n",
    "        return False\n",
    "    if atol == 0.0:\n",
    "        return np.array_equal(a, b)\n",
    "    return np.allclose(a, b, atol=atol, rtol=0.0)\n",
    "\n",
    "# ----------------------------\n",
    "# Build X on CROPPED point list (for later saving/plots)\n",
    "# ----------------------------\n",
    "times = list(range(TIME_STEP_START, TIME_STEP_END + 1))\n",
    "\n",
    "ref_path = field_csv_path(BASE_DIR, PHI, LAT_SIZE, times[0], POST)\n",
    "coords_ref_full, snap0_full = read_field_sorted(ref_path, VAR_NAME, SORT_COLS)\n",
    "\n",
    "mask_x = coords_ref_full[:, 0] > X_THESHOLD\n",
    "coords_ref = coords_ref_full[mask_x]\n",
    "snap0 = snap0_full[mask_x]\n",
    "\n",
    "snapshots = [snap0]\n",
    "for t in times[1:]:\n",
    "    p = field_csv_path(BASE_DIR, PHI, LAT_SIZE, t, POST)\n",
    "    coords_t_full, snap_t_full = read_field_sorted(p, VAR_NAME, SORT_COLS)\n",
    "\n",
    "    if coords_t_full.shape[0] != coords_ref_full.shape[0]:\n",
    "        raise ValueError(f\"Full point count changed at t={t}: {coords_t_full.shape[0]} vs {coords_ref_full.shape[0]}\")\n",
    "\n",
    "    if not coords_match(coords_t_full, coords_ref_full, COORD_TOL):\n",
    "        raise ValueError(f\"Full coordinates mismatch at t={t}. Sorting/interpolation/mesh changed.\")\n",
    "\n",
    "    snapshots.append(snap_t_full[mask_x])\n",
    "\n",
    "# X_points: (n_points_cropped, n_snaps)\n",
    "X_points = np.stack(snapshots, axis=1).astype(np.float64)\n",
    "n_points, n_snaps = X_points.shape\n",
    "print(f\"Read snapshots: n_points_cropped={n_points}, n_snaps={n_snaps}, x>{X_THESHOLD}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Regrid to uniform (ny,nx) for FFT/FNO\n",
    "# ----------------------------\n",
    "# Define uniform grid on bounding box of CROPPED coordinates\n",
    "x_min, x_max = float(coords_ref[:, 0].min()), float(coords_ref[:, 0].max())\n",
    "y_min, y_max = float(coords_ref[:, 1].min()), float(coords_ref[:, 1].max())\n",
    "\n",
    "xs_u = np.linspace(x_min, x_max, GRID_NX, dtype=np.float64)\n",
    "ys_u = np.linspace(y_min, y_max, GRID_NY, dtype=np.float64)\n",
    "Xg, Yg = np.meshgrid(xs_u, ys_u)  # shapes (ny,nx)\n",
    "\n",
    "# Triangulation of cropped points for interpolation\n",
    "tri = mtri.Triangulation(coords_ref[:, 0], coords_ref[:, 1])\n",
    "\n",
    "def points_to_uniform_grid(vals_points: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Linear triangulation interpolation onto (ys_u,xs_u) grid.\"\"\"\n",
    "    interp = mtri.LinearTriInterpolator(tri, vals_points.astype(np.float64))\n",
    "    Zm = interp(Xg, Yg)  # masked array\n",
    "    Z = np.asarray(Zm.filled(np.nan), dtype=np.float32)\n",
    "    if np.isnan(Z).any():\n",
    "        fill = np.nanmean(Z)\n",
    "        if not np.isfinite(fill):\n",
    "            fill = 0.0\n",
    "        Z = np.nan_to_num(Z, nan=float(fill)).astype(np.float32)\n",
    "    return Z  # (ny,nx)\n",
    "\n",
    "# Build gridded time sequence: U[t] = (ny,nx)\n",
    "U = np.stack([points_to_uniform_grid(X_points[:, k]) for k in range(n_snaps)], axis=0).astype(np.float32)\n",
    "# U: (T, ny, nx)\n",
    "T_total, ny, nx = U.shape\n",
    "print(f\"Uniform grid sequence: U.shape={U.shape} (T,ny,nx)\")\n",
    "\n",
    "# Normalize per-pixel over time (helps training stability)\n",
    "U_mean = U.mean(axis=0, keepdims=True)            # (1,ny,nx)\n",
    "U_std  = U.std(axis=0, keepdims=True) + 1e-6      # (1,ny,nx)\n",
    "U_n = (U - U_mean) / U_std                        # (T,ny,nx)\n",
    "\n",
    "# Add channel dim for CNN/FNO: (T,1,ny,nx)\n",
    "U_n = U_n[:, None, :, :].astype(np.float32)\n",
    "\n",
    "# Convenience: map uniform-grid field back to your cropped point list (for saving/metrics)\n",
    "def uniform_grid_to_points_bilinear(Z: np.ndarray, coords_xy: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Z: (ny,nx) on ys_u/xs_u\n",
    "    coords_xy: (n_points,2)\n",
    "    returns values at coords via bilinear interpolation\n",
    "    \"\"\"\n",
    "    x = coords_xy[:, 0].astype(np.float64)\n",
    "    y = coords_xy[:, 1].astype(np.float64)\n",
    "\n",
    "    # fractional indices\n",
    "    ix = np.searchsorted(xs_u, x) - 1\n",
    "    iy = np.searchsorted(ys_u, y) - 1\n",
    "    ix = np.clip(ix, 0, nx - 2)\n",
    "    iy = np.clip(iy, 0, ny - 2)\n",
    "\n",
    "    x0 = xs_u[ix]\n",
    "    x1 = xs_u[ix + 1]\n",
    "    y0 = ys_u[iy]\n",
    "    y1 = ys_u[iy + 1]\n",
    "\n",
    "    tx = (x - x0) / (x1 - x0 + 1e-30)\n",
    "    ty = (y - y0) / (y1 - y0 + 1e-30)\n",
    "\n",
    "    z00 = Z[iy, ix]\n",
    "    z10 = Z[iy, ix + 1]\n",
    "    z01 = Z[iy + 1, ix]\n",
    "    z11 = Z[iy + 1, ix + 1]\n",
    "\n",
    "    z0 = (1 - tx) * z00 + tx * z10\n",
    "    z1 = (1 - tx) * z01 + tx * z11\n",
    "    return ((1 - ty) * z0 + ty * z1).astype(np.float64)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from flamekit.io_fields import field_path\n",
    "from flamekit.io_fronts import Case\n",
    "# ============================================================\n",
    "# BOX 2/3 — kFNO (paper-style: L -> H -> K* (Koopman-like A iterated) -> Q* -> P*)\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# ----------------------------\n",
    "# kFNO SETTINGS\n",
    "# ----------------------------\n",
    "DEVICE = \"cuda\"\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "if DEVICE == \"cuda\" and not torch.cuda.is_available():\n",
    "    DEVICE = \"cpu\"\n",
    "device = torch.device(DEVICE)\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "N_PRED = 4              # n-step operator output length (t+1..t+n)\n",
    "EPOCHS = 800\n",
    "BATCH_SIZE = 6\n",
    "BATCHES_PER_EPOCH = 60\n",
    "\n",
    "LR = 2e-3\n",
    "WEIGHT_DECAY = 1e-7\n",
    "\n",
    "WIDTH = 48              # hidden channels\n",
    "N_H_LAYERS = 4           # layers in H (baseline FNO trunk)\n",
    "N_Q_LAYERS = 1           # layers in Q*\n",
    "MODES_X = 20\n",
    "MODES_Y = 20\n",
    "\n",
    "ADD_COORDS = True        # common in FNO; helps (still OK with periodic BCs)\n",
    "ALPHA_SKIP = 1.0         # paper has alpha controlling skip connection in Fourier layer; 0=no skip, 1=full skip :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "# Koopman-like advancement operator A in hidden space:\n",
    "# \"linear\"  -> one Fourier layer w/o nonlinearity\n",
    "# \"nonlinear\" -> two Fourier layers with nonlinearity between (more expressive) :contentReference[oaicite:2]{index=2}\n",
    "A_TYPE = \"linear\"        # or \"nonlinear\"\n",
    "\n",
    "# Loss in normalized space\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "U_torch = torch.from_numpy(U_n).to(device)  # (T,1,ny,nx)\n",
    "\n",
    "if N_PRED >= T_total:\n",
    "    raise ValueError(f\"N_PRED={N_PRED} must be < number of snapshots T={T_total}.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Core FNO building blocks\n",
    "# ----------------------------\n",
    "class SpectralConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    2D spectral convolution: keep low Fourier modes and apply learned complex weights.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, modes_x: int, modes_y: int) -> None:\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes_x = modes_x\n",
    "        self.modes_y = modes_y\n",
    "\n",
    "        # complex weights for truncated modes\n",
    "        scale = 1.0 / (in_channels * out_channels)\n",
    "        self.w = nn.Parameter(scale * torch.randn(in_channels, out_channels, modes_y, modes_x, dtype=torch.cfloat))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B,C,ny,nx)\n",
    "        B, C, ny_, nx_ = x.shape\n",
    "        x_ft = torch.fft.rfft2(x, norm=\"ortho\")  # (B,C,ny, nx//2+1)\n",
    "\n",
    "        out_ft = torch.zeros(B, self.out_channels, ny_, nx_ // 2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "\n",
    "        my = min(self.modes_y, ny_)\n",
    "        mx = min(self.modes_x, nx_ // 2 + 1)\n",
    "\n",
    "        # low modes (top-left block)\n",
    "        out_ft[:, :, :my, :mx] = torch.einsum(\"bcyx,co yx->boyx\", x_ft[:, :, :my, :mx], self.w[:, :, :my, :mx])\n",
    "\n",
    "        out = torch.fft.irfft2(out_ft, s=(ny_, nx_), norm=\"ortho\")\n",
    "        return out  # (B,outC,ny,nx)\n",
    "\n",
    "class FourierLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper-like Fourier layer:\n",
    "      u_{l+1} = σ( α * W(u_l) + (1-α) * F^{-1}(R(F(u_l))) + b )\n",
    "    where α controls skip connection contribution. :contentReference[oaicite:3]{index=3}\n",
    "    \"\"\"\n",
    "    def __init__(self, width: int, modes_x: int, modes_y: int, alpha: float, activation: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.alpha = float(alpha)\n",
    "        self.spectral = SpectralConv2d(width, width, modes_x, modes_y)\n",
    "        self.pointwise = nn.Conv2d(width, width, kernel_size=1)\n",
    "        self.bias = nn.Parameter(torch.zeros(1, width, 1, 1))\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y_spec = self.spectral(x)\n",
    "        y_lin = self.pointwise(x)\n",
    "        y = self.alpha * y_lin + (1.0 - self.alpha) * y_spec + self.bias\n",
    "        if self.activation:\n",
    "            return F.gelu(y)\n",
    "        return y\n",
    "\n",
    "class FNOBlock(nn.Module):\n",
    "    def __init__(self, width: int, modes_x: int, modes_y: int, n_layers: int, alpha: float, activation_last: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            act = True\n",
    "            if i == n_layers - 1 and not activation_last:\n",
    "                act = False\n",
    "            layers.append(FourierLayer(width, modes_x, modes_y, alpha=alpha, activation=act))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "# ----------------------------\n",
    "# kFNO model\n",
    "# ----------------------------\n",
    "class kFNO(nn.Module):\n",
    "    \"\"\"\n",
    "    Outputs n-step predictions in one forward pass:\n",
    "      input: u(t)  -> outputs: [u(t+1), ..., u(t+n)]\n",
    "    Architecture (paper):\n",
    "      L -> H -> K* (iterate A) -> Q* -> P*  :contentReference[oaicite:4]{index=4}\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: int,\n",
    "        modes_x: int,\n",
    "        modes_y: int,\n",
    "        n_h_layers: int,\n",
    "        n_q_layers: int,\n",
    "        n_pred: int,\n",
    "        add_coords: bool,\n",
    "        alpha_skip: float,\n",
    "        a_type: str = \"linear\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.n_pred = int(n_pred)\n",
    "        self.add_coords = bool(add_coords)\n",
    "\n",
    "        in_ch = 1 + (2 if self.add_coords else 0)\n",
    "        self.lift = nn.Conv2d(in_ch, width, kernel_size=1)\n",
    "\n",
    "        # H: baseline FNO trunk\n",
    "        self.H = FNOBlock(width, modes_x, modes_y, n_layers=n_h_layers, alpha=alpha_skip, activation_last=True)\n",
    "\n",
    "        # A: Koopman-like advancement operator in hidden space (shared across steps) :contentReference[oaicite:5]{index=5}\n",
    "        if a_type == \"linear\":\n",
    "            self.A = FourierLayer(width, modes_x, modes_y, alpha=alpha_skip, activation=False)\n",
    "        elif a_type == \"nonlinear\":\n",
    "            self.A = nn.Sequential(\n",
    "                FourierLayer(width, modes_x, modes_y, alpha=alpha_skip, activation=True),\n",
    "                FourierLayer(width, modes_x, modes_y, alpha=alpha_skip, activation=False),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"a_type must be 'linear' or 'nonlinear'.\")\n",
    "\n",
    "        # Q*: refinement on advanced hidden states\n",
    "        self.Q = FNOBlock(width, modes_x, modes_y, n_layers=n_q_layers, alpha=alpha_skip, activation_last=True) if n_q_layers > 0 else nn.Identity()\n",
    "\n",
    "        # P*: project to physical field\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(width, width, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(width, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, u0: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        u0: (B,1,ny,nx)\n",
    "        returns: (B,n_pred,1,ny,nx) predictions for steps 1..n_pred\n",
    "        \"\"\"\n",
    "        B, C, ny_, nx_ = u0.shape\n",
    "\n",
    "        if self.add_coords:\n",
    "            # normalized coordinate channels in [0,1]\n",
    "            xs = torch.linspace(0, 1, nx_, device=u0.device).view(1, 1, 1, nx_).expand(B, 1, ny_, nx_)\n",
    "            ys = torch.linspace(0, 1, ny_, device=u0.device).view(1, 1, ny_, 1).expand(B, 1, ny_, nx_)\n",
    "            u_in = torch.cat([u0, xs, ys], dim=1)\n",
    "        else:\n",
    "            u_in = u0\n",
    "\n",
    "        e = self.lift(u_in)   # L\n",
    "        e = self.H(e)         # H\n",
    "\n",
    "        outs = []\n",
    "        for _k in range(self.n_pred):\n",
    "            e = self.A(e)     # K*: advance hidden state iteratively (Koopman-like A) :contentReference[oaicite:6]{index=6}\n",
    "            ek = self.Q(e)    # Q*: refine\n",
    "            uk = self.proj(ek)  # P*: project\n",
    "            outs.append(uk)\n",
    "\n",
    "        return torch.stack(outs, dim=1)\n",
    "\n",
    "# ----------------------------\n",
    "# Training utilities (learn extended n-step operator)\n",
    "# ----------------------------\n",
    "def sample_batch_starts(T: int, n_pred: int, batch_size: int) -> np.ndarray:\n",
    "    # need u(t) and targets u(t+1..t+n_pred)\n",
    "    max_start = T - (n_pred + 1)\n",
    "    if max_start < 0:\n",
    "        raise ValueError(\"Not enough snapshots for chosen N_PRED.\")\n",
    "    return np.random.randint(0, max_start + 1, size=batch_size)\n",
    "\n",
    "def rel_l2(a: torch.Tensor, b: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n",
    "    # relative L2 over all pixels + channels + batch\n",
    "    num = torch.linalg.norm(a - b)\n",
    "    den = torch.linalg.norm(b) + eps\n",
    "    return num / den\n",
    "\n",
    "# ----------------------------\n",
    "# Train\n",
    "# ----------------------------\n",
    "model = kFNO(\n",
    "    width=WIDTH,\n",
    "    modes_x=MODES_X,\n",
    "    modes_y=MODES_Y,\n",
    "    n_h_layers=N_H_LAYERS,\n",
    "    n_q_layers=N_Q_LAYERS,\n",
    "    n_pred=N_PRED,\n",
    "    add_coords=ADD_COORDS,\n",
    "    alpha_skip=ALPHA_SKIP,\n",
    "    a_type=A_TYPE,\n",
    ").to(device)\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "print(f\"kFNO: WIDTH={WIDTH}, modes=({MODES_Y},{MODES_X}), N_PRED={N_PRED}, A_TYPE={A_TYPE}\")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    rerrs = []\n",
    "\n",
    "    for _ in range(BATCHES_PER_EPOCH):\n",
    "        idx0 = sample_batch_starts(T_total, N_PRED, BATCH_SIZE)\n",
    "\n",
    "        u0 = U_torch[idx0, :, :, :]                              # (B,1,ny,nx)\n",
    "        tgt = torch.stack([U_torch[idx0 + j, :, :, :] for j in range(1, N_PRED + 1)], dim=1)  # (B,N,1,ny,nx)\n",
    "\n",
    "        pred = model(u0)                                         # (B,N,1,ny,nx)\n",
    "\n",
    "        loss = mse(pred, tgt)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        rerrs.append(float(rel_l2(pred, tgt).detach().cpu().item()))\n",
    "\n",
    "    if epoch == 1 or epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch:4d}/{EPOCHS} | MSE={np.mean(losses):.3e} | relL2={np.mean(rerrs):.3e}\")\n",
    "\n",
    "# ----------------------------\n",
    "# One-step forecast at next timestep (t_next = TIME_STEP_END + 1)\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "t_next = TIME_STEP_END + 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    u_last = U_torch[-1:, :, :, :]       # normalized, (1,1,ny,nx)\n",
    "    pred_seq = model(u_last)             # (1,N_PRED,1,ny,nx)\n",
    "    u1_pred_n = pred_seq[:, 0, 0, :, :].cpu().numpy()[0]  # first-step prediction on uniform grid, normalized\n",
    "\n",
    "# Undo normalization to physical T on uniform grid\n",
    "T_pred_grid = (u1_pred_n * U_std[0] + U_mean[0]).astype(np.float64)  # (ny,nx)\n",
    "\n",
    "# Map back to cropped point list for saving/metrics\n",
    "T_pred_points = uniform_grid_to_points_bilinear(T_pred_grid, coords_ref)\n",
    "\n",
    "# Save prediction alongside coords (cropped)\n",
    "out_dir = field_path(Case(base_dir=BASE_DIR, phi=PHI, lat_size=LAT_SIZE, time_step=0, post=POST)).parent\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out = pd.DataFrame(coords_ref, columns=SORT_COLS)\n",
    "out[f\"{VAR_NAME}_pred\"] = T_pred_points\n",
    "out_path = out_dir / f\"kfno_pred_{VAR_NAME}_{t_next}_xgt{int(X_THESHOLD)}.csv\"\n",
    "out.to_csv(out_path, index=False)\n",
    "print(\"Wrote:\", out_path)\n"
   ],
   "id": "b75336a46105a5b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# BOX 3/3 — Plotting (pred/true fields + error maps + Ttrue vs Tpred)\n",
    "# ============================================================\n",
    "\n",
    "# Read true next snapshot (if exists), validate full coords, then crop\n",
    "path_true = field_csv_path(BASE_DIR, PHI, LAT_SIZE, t_next, POST)\n",
    "\n",
    "if path_true.exists():\n",
    "    coords_true_full, snap_true_full = read_field_sorted(path_true, VAR_NAME, SORT_COLS)\n",
    "\n",
    "    if coords_true_full.shape[0] != coords_ref_full.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"True next-step has different full point count: {coords_true_full.shape[0]} vs {coords_ref_full.shape[0]}\"\n",
    "        )\n",
    "    if not coords_match(coords_true_full, coords_ref_full, COORD_TOL):\n",
    "        raise ValueError(\"True next-step full coordinates changed; cannot compare directly.\")\n",
    "\n",
    "    T_true_points = snap_true_full[mask_x].astype(np.float64)\n",
    "\n",
    "    # Errors on points\n",
    "    err = T_pred_points - T_true_points\n",
    "    abs_err = np.abs(err)\n",
    "\n",
    "    rmse = float(np.sqrt(np.mean(err**2)))\n",
    "    rel_l2 = float(np.linalg.norm(err) / (np.linalg.norm(T_true_points) + 1e-12))\n",
    "    print(f\"Next-step RMSE: {rmse:.6e}\")\n",
    "    print(f\"Next-step relative L2 error: {rel_l2:.6e}\")\n",
    "\n",
    "    # Save error CSV (cropped)\n",
    "    out_err = pd.DataFrame(coords_ref, columns=SORT_COLS)\n",
    "    out_err[f\"{VAR_NAME}_true\"] = T_true_points\n",
    "    out_err[f\"{VAR_NAME}_pred\"] = T_pred_points\n",
    "    out_err[\"err\"] = err\n",
    "    out_err[\"abs_err\"] = abs_err\n",
    "    err_path = out_dir / f\"kfno_err_{VAR_NAME}_{t_next}_xgt{int(X_THESHOLD)}.csv\"\n",
    "    out_err.to_csv(err_path, index=False)\n",
    "    print(\"Wrote:\", err_path)\n",
    "\n",
    "    # Triangulation for XY plots\n",
    "    x = coords_ref[:, 0].astype(float)\n",
    "    y = coords_ref[:, 1].astype(float)\n",
    "    tri_xy = mtri.Triangulation(x, y)\n",
    "    try:\n",
    "        analyzer = mtri.TriAnalyzer(tri_xy)\n",
    "        tri_xy.set_mask(analyzer.get_flat_tri_mask(min_circle_ratio=0.02))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    def tricontour_field(vals: np.ndarray, title: str, cbar_label: str, vmin=None, vmax=None) -> None:\n",
    "        fig = plt.figure(figsize=(7.2, 5.8))\n",
    "        ax = fig.add_subplot(111)\n",
    "        cf = ax.tricontourf(tri_xy, vals, levels=60, vmin=vmin, vmax=vmax)\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "        ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "        ax.set_title(title)\n",
    "        cbar = fig.colorbar(cf, ax=ax, orientation=\"horizontal\", pad=0.08, fraction=0.06)\n",
    "        cbar.set_label(cbar_label)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Shared scale for true/pred fields\n",
    "    vmin = float(min(np.percentile(T_true_points, 0.5), np.percentile(T_pred_points, 0.5)))\n",
    "    vmax = float(max(np.percentile(T_true_points, 99.5), np.percentile(T_pred_points, 99.5)))\n",
    "\n",
    "    tricontour_field(\n",
    "        T_pred_points,\n",
    "        title=f\"{VAR_NAME} PRED (kFNO) at t={t_next} (x > {X_THESHOLD})\",\n",
    "        cbar_label=f\"{VAR_NAME} (pred)\",\n",
    "        vmin=vmin, vmax=vmax,\n",
    "    )\n",
    "    tricontour_field(\n",
    "        T_true_points,\n",
    "        title=f\"{VAR_NAME} TRUE at t={t_next} (x > {X_THESHOLD})\",\n",
    "        cbar_label=f\"{VAR_NAME} (true)\",\n",
    "        vmin=vmin, vmax=vmax,\n",
    "    )\n",
    "\n",
    "    # Requested: Ttrue vs Tpred scatter\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(T_true_points, T_pred_points, s=2)\n",
    "    lo = float(min(T_true_points.min(), T_pred_points.min()))\n",
    "    hi = float(max(T_true_points.max(), T_pred_points.max()))\n",
    "    plt.plot([lo, hi], [lo, hi], linestyle=\"--\")\n",
    "    plt.xlabel(f\"{VAR_NAME}_true\")\n",
    "    plt.ylabel(f\"{VAR_NAME}_pred\")\n",
    "    plt.title(f\"{VAR_NAME}_true vs {VAR_NAME}_pred at t={t_next} (x > {X_THESHOLD})\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Error maps\n",
    "    vmax_signed = float(np.percentile(np.abs(err), 99.0)) + 1e-30\n",
    "    vmax_abs = float(np.percentile(abs_err, 99.0)) + 1e-30\n",
    "\n",
    "    tricontour_field(\n",
    "        err,\n",
    "        title=f\"{VAR_NAME} signed error (pred - true) at t={t_next} (x > {X_THESHOLD})\",\n",
    "        cbar_label=\"Signed error\",\n",
    "        vmin=-vmax_signed, vmax=vmax_signed,\n",
    "    )\n",
    "    tricontour_field(\n",
    "        abs_err,\n",
    "        title=f\"{VAR_NAME} absolute error |pred - true| at t={t_next} (x > {X_THESHOLD})\",\n",
    "        cbar_label=\"Absolute error\",\n",
    "        vmin=0.0, vmax=vmax_abs,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"True next-step file does not exist; plotting only prediction.\")\n",
    "    # Plot prediction anyway\n",
    "    x = coords_ref[:, 0].astype(float)\n",
    "    y = coords_ref[:, 1].astype(float)\n",
    "    tri_xy = mtri.Triangulation(x, y)\n",
    "    fig = plt.figure(figsize=(7.2, 5.8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cf = ax.tricontourf(tri_xy, T_pred_points, levels=60)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "    ax.set_title(f\"{VAR_NAME} PRED (kFNO) at t={t_next} (x > {X_THESHOLD})\")\n",
    "    cbar = fig.colorbar(cf, ax=ax, orientation=\"horizontal\", pad=0.08, fraction=0.06)\n",
    "    cbar.set_label(f\"{VAR_NAME} (pred)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "643a284af0aa307e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}