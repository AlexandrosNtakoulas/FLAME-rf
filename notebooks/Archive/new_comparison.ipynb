{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-16T14:26:53.161376Z",
     "start_time": "2025-12-16T14:26:52.030366Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RESULTS_ROOT = Path(\"../results/gmm_stability\")\n",
    "RUNS_CSV = RESULTS_ROOT / \"runs.csv\"\n",
    "\n",
    "# ---------- utilities ----------\n",
    "def load_importance_long(run_id: str) -> pd.DataFrame:\n",
    "    run_dir = RESULTS_ROOT / f\"run_{run_id}\"\n",
    "    imp = pd.read_csv(run_dir / \"importance_long.csv\")\n",
    "    return imp\n",
    "\n",
    "def load_summary(run_id: str) -> pd.DataFrame:\n",
    "    run_dir = RESULTS_ROOT / f\"run_{run_id}\"\n",
    "    return pd.read_csv(run_dir / \"summary_clusters.csv\")\n",
    "\n",
    "def build_signatures(run_id: str, feature_universe: list[str] | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a wide matrix:\n",
    "      index: cluster\n",
    "      columns: features\n",
    "      values: normalized importance (L1)\n",
    "    \"\"\"\n",
    "    imp = load_importance_long(run_id)\n",
    "    if imp.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # pivot to wide\n",
    "    wide = imp.pivot_table(index=\"cluster\", columns=\"feature\", values=\"importance\", aggfunc=\"mean\").fillna(0.0)\n",
    "\n",
    "    if feature_universe is not None:\n",
    "        # ensure same columns across runs\n",
    "        for f in feature_universe:\n",
    "            if f not in wide.columns:\n",
    "                wide[f] = 0.0\n",
    "        wide = wide[feature_universe]\n",
    "\n",
    "    # L1 normalize per cluster\n",
    "    s = wide.sum(axis=1).replace(0.0, np.nan)\n",
    "    wide = wide.div(s, axis=0).fillna(0.0)\n",
    "    return wide\n",
    "\n",
    "def cosine_sim_matrix(A: np.ndarray, B: np.ndarray) -> np.ndarray:\n",
    "    # rows are vectors\n",
    "    An = A / (np.linalg.norm(A, axis=1, keepdims=True) + 1e-12)\n",
    "    Bn = B / (np.linalg.norm(B, axis=1, keepdims=True) + 1e-12)\n",
    "    return An @ Bn.T\n",
    "\n",
    "def match_clusters_by_importance(sig_a: pd.DataFrame, sig_b: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Match clusters between two runs by maximizing cosine similarity between signatures.\n",
    "    Returns DataFrame: cluster_A, cluster_B, similarity\n",
    "    \"\"\"\n",
    "    if sig_a.empty or sig_b.empty:\n",
    "        return pd.DataFrame(columns=[\"cluster_A\", \"cluster_B\", \"similarity\"])\n",
    "\n",
    "    A = sig_a.sort_index()\n",
    "    B = sig_b.sort_index()\n",
    "\n",
    "    S = cosine_sim_matrix(A.to_numpy(), B.to_numpy())  # similarity matrix\n",
    "\n",
    "    try:\n",
    "        from scipy.optimize import linear_sum_assignment  # type: ignore\n",
    "        # Hungarian solves min cost -> use cost = 1 - similarity\n",
    "        r, c = linear_sum_assignment(1.0 - S)\n",
    "        pairs = [(int(A.index[i]), int(B.index[j]), float(S[i, j])) for i, j in zip(r, c)]\n",
    "    except Exception:\n",
    "        # greedy fallback\n",
    "        pairs = []\n",
    "        used_j = set()\n",
    "        for i in range(S.shape[0]):\n",
    "            j = int(np.argmax([S[i, jj] if jj not in used_j else -np.inf for jj in range(S.shape[1])]))\n",
    "            used_j.add(j)\n",
    "            pairs.append((int(A.index[i]), int(B.index[j]), float(S[i, j])))\n",
    "\n",
    "    return pd.DataFrame(pairs, columns=[\"cluster_A\", \"cluster_B\", \"similarity\"]).sort_values(\"similarity\", ascending=False)\n",
    "\n",
    "def top_feature(sig: pd.DataFrame, cl: int) -> str | None:\n",
    "    if cl not in sig.index:\n",
    "        return None\n",
    "    s = sig.loc[cl]\n",
    "    if (s.values <= 0).all():\n",
    "        return None\n",
    "    return str(s.idxmax())\n",
    "\n",
    "def topk_set(sig: pd.DataFrame, cl: int, k: int = 5) -> set[str]:\n",
    "    if cl not in sig.index:\n",
    "        return set()\n",
    "    s = sig.loc[cl].sort_values(ascending=False)\n",
    "    s = s[s > 0]\n",
    "    return set(map(str, s.head(k).index))\n",
    "\n",
    "def weighted_mean_similarity(mapping: pd.DataFrame, sum_a: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Weight similarities by cluster size from run A (n).\n",
    "    \"\"\"\n",
    "    if mapping.empty or sum_a.empty:\n",
    "        return np.nan\n",
    "    w = sum_a.set_index(\"cluster\")[\"n\"].to_dict()\n",
    "    mapping = mapping.copy()\n",
    "    mapping[\"w\"] = mapping[\"cluster_A\"].map(w).fillna(0.0)\n",
    "    if mapping[\"w\"].sum() == 0:\n",
    "        return float(mapping[\"similarity\"].mean())\n",
    "    return float((mapping[\"similarity\"] * mapping[\"w\"]).sum() / mapping[\"w\"].sum())\n",
    "\n",
    "# ---------- main: compare all pairs ----------\n",
    "runs_df = pd.read_csv(RUNS_CSV)\n",
    "run_ids = runs_df[\"run_id\"].tolist()\n",
    "\n",
    "# Build a common feature universe across all runs (ensures signatures align)\n",
    "all_feats = set()\n",
    "for rid in run_ids:\n",
    "    imp = load_importance_long(rid)\n",
    "    all_feats.update(imp[\"feature\"].unique().tolist())\n",
    "feature_universe = sorted(all_feats)\n",
    "\n",
    "results = []\n",
    "for i in range(len(run_ids)):\n",
    "    for j in range(i + 1, len(run_ids)):\n",
    "        ra, rb = run_ids[i], run_ids[j]\n",
    "        sig_a = build_signatures(ra, feature_universe=feature_universe)\n",
    "        sig_b = build_signatures(rb, feature_universe=feature_universe)\n",
    "        sum_a = load_summary(ra)\n",
    "\n",
    "        mapping = match_clusters_by_importance(sig_a, sig_b)\n",
    "\n",
    "        # metrics\n",
    "        mean_sim = float(mapping[\"similarity\"].mean()) if not mapping.empty else np.nan\n",
    "        wmean_sim = weighted_mean_similarity(mapping, sum_a)\n",
    "\n",
    "        # top-1 agreement on matched clusters\n",
    "        top1_match = []\n",
    "        top5_jacc = []\n",
    "        for _, row in mapping.iterrows():\n",
    "            ca = int(row[\"cluster_A\"])\n",
    "            cb = int(row[\"cluster_B\"])\n",
    "            fa = top_feature(sig_a, ca)\n",
    "            fb = top_feature(sig_b, cb)\n",
    "            top1_match.append(1 if (fa is not None and fa == fb) else 0)\n",
    "\n",
    "            A5 = topk_set(sig_a, ca, k=5)\n",
    "            B5 = topk_set(sig_b, cb, k=5)\n",
    "            top5_jacc.append(len(A5 & B5) / len(A5 | B5) if (A5 or B5) else np.nan)\n",
    "\n",
    "        results.append({\n",
    "            \"run_a\": ra,\n",
    "            \"run_b\": rb,\n",
    "            \"mean_cluster_sim\": mean_sim,\n",
    "            \"weighted_mean_cluster_sim\": wmean_sim,\n",
    "            \"top1_agreement_rate\": float(np.nanmean(top1_match)) if len(top1_match) else np.nan,\n",
    "            \"mean_top5_jaccard\": float(np.nanmean(top5_jacc)) if len(top5_jacc) else np.nan,\n",
    "        })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "out_csv = RESULTS_ROOT / \"comparisons_by_importance_signatures.csv\"\n",
    "res_df.to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"Saved: {out_csv}\")\n",
    "display(res_df.sort_values(\"weighted_mean_cluster_sim\", ascending=False).head(10))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\results\\gmm_stability\\comparisons_by_importance_signatures.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                run_a  \\\n",
       "5   20251216_150031_phi0.40_lat200_t230_iso4.5_k5_...   \n",
       "4   20251216_150031_phi0.40_lat200_t230_iso4.5_k5_...   \n",
       "27  20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...   \n",
       "6   20251216_150031_phi0.40_lat200_t230_iso4.5_k5_...   \n",
       "25  20251216_151517_phi0.40_lat050_t335_iso4.5_k5_...   \n",
       "8   20251216_150226_phi0.40_lat025_t335_iso4.5_k5_...   \n",
       "1   20251216_150031_phi0.40_lat200_t230_iso4.5_k5_...   \n",
       "11  20251216_150226_phi0.40_lat025_t335_iso4.5_k5_...   \n",
       "20  20251216_150607_phi0.40_lat025_t100_iso4.5_k5_...   \n",
       "17  20251216_150557_phi0.40_lat025_t238_iso4.5_k5_...   \n",
       "\n",
       "                                                run_b  mean_cluster_sim  \\\n",
       "5   20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...          0.902453   \n",
       "4   20251216_151517_phi0.40_lat050_t335_iso4.5_k5_...          0.755676   \n",
       "27  20251216_152542_phi0.40_lat100_t140_iso4.5_k5_...          0.666143   \n",
       "6   20251216_152542_phi0.40_lat100_t140_iso4.5_k5_...          0.666221   \n",
       "25  20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...          0.772498   \n",
       "8   20251216_150607_phi0.40_lat025_t100_iso4.5_k5_...          0.535983   \n",
       "1   20251216_150557_phi0.40_lat025_t238_iso4.5_k5_...          0.438925   \n",
       "11  20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...          0.468194   \n",
       "20  20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...          0.479036   \n",
       "17  20251216_152542_phi0.40_lat100_t140_iso4.5_k5_...          0.504918   \n",
       "\n",
       "    weighted_mean_cluster_sim  top1_agreement_rate  mean_top5_jaccard  \n",
       "5                    0.931836                  1.0           0.357143  \n",
       "4                    0.791328                  0.8           0.354762  \n",
       "27                   0.768228                  0.4           0.404762  \n",
       "6                    0.743761                  0.4           0.285714  \n",
       "25                   0.699077                  0.8           0.376984  \n",
       "8                    0.586234                  0.6           0.088889  \n",
       "1                    0.573945                  0.4           0.215873  \n",
       "11                   0.534468                  0.4           0.207937  \n",
       "20                   0.515167                  0.4           0.233333  \n",
       "17                   0.506722                  0.4           0.207937  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_a</th>\n",
       "      <th>run_b</th>\n",
       "      <th>mean_cluster_sim</th>\n",
       "      <th>weighted_mean_cluster_sim</th>\n",
       "      <th>top1_agreement_rate</th>\n",
       "      <th>mean_top5_jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251216_150031_phi0.40_lat200_t230_iso4.5_k5_...</td>\n",
       "      <td>20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...</td>\n",
       "      <td>0.902453</td>\n",
       "      <td>0.931836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251216_150031_phi0.40_lat200_t230_iso4.5_k5_...</td>\n",
       "      <td>20251216_151517_phi0.40_lat050_t335_iso4.5_k5_...</td>\n",
       "      <td>0.755676</td>\n",
       "      <td>0.791328</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.354762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...</td>\n",
       "      <td>20251216_152542_phi0.40_lat100_t140_iso4.5_k5_...</td>\n",
       "      <td>0.666143</td>\n",
       "      <td>0.768228</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.404762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251216_150031_phi0.40_lat200_t230_iso4.5_k5_...</td>\n",
       "      <td>20251216_152542_phi0.40_lat100_t140_iso4.5_k5_...</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>0.743761</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251216_151517_phi0.40_lat050_t335_iso4.5_k5_...</td>\n",
       "      <td>20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...</td>\n",
       "      <td>0.772498</td>\n",
       "      <td>0.699077</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.376984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251216_150226_phi0.40_lat025_t335_iso4.5_k5_...</td>\n",
       "      <td>20251216_150607_phi0.40_lat025_t100_iso4.5_k5_...</td>\n",
       "      <td>0.535983</td>\n",
       "      <td>0.586234</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251216_150031_phi0.40_lat200_t230_iso4.5_k5_...</td>\n",
       "      <td>20251216_150557_phi0.40_lat025_t238_iso4.5_k5_...</td>\n",
       "      <td>0.438925</td>\n",
       "      <td>0.573945</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.215873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251216_150226_phi0.40_lat025_t335_iso4.5_k5_...</td>\n",
       "      <td>20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...</td>\n",
       "      <td>0.468194</td>\n",
       "      <td>0.534468</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.207937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251216_150607_phi0.40_lat025_t100_iso4.5_k5_...</td>\n",
       "      <td>20251216_151757_phi0.40_lat100_t211_iso4.5_k5_...</td>\n",
       "      <td>0.479036</td>\n",
       "      <td>0.515167</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251216_150557_phi0.40_lat025_t238_iso4.5_k5_...</td>\n",
       "      <td>20251216_152542_phi0.40_lat100_t140_iso4.5_k5_...</td>\n",
       "      <td>0.504918</td>\n",
       "      <td>0.506722</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.207937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37a5d135dda9d684"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
