{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-24T10:07:05.835972800Z",
     "start_time": "2025-12-24T10:04:46.769900Z"
    }
   },
   "source": [
    "# ============================================================\n",
    "# BOX 1/3 — Reading CSV snapshots + consistent crop (NO gridding)\n",
    "# ============================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "from flamekit.io_fields import field_path\n",
    "from flamekit.io_fronts import Case\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "# ----------------------------\n",
    "# USER SETTINGS\n",
    "# ----------------------------\n",
    "TIME_STEP_START = 200\n",
    "TIME_STEP_END   = 269\n",
    "\n",
    "PHI      = 0.40\n",
    "LAT_SIZE = \"025\"\n",
    "POST     = True\n",
    "\n",
    "BASE_DIR  = Path(\"../isocontours\")\n",
    "VAR_NAME  = \"T\"\n",
    "SORT_COLS = [\"x\", \"y\"]\n",
    "COORD_TOL = 0.0\n",
    "\n",
    "X_THESHOLD = 300  # keep only x > threshold (consistent)\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def field_csv_path(base_dir: Path, phi: float, lat_size: str, time_step: int, post: bool) -> Path:\n",
    "    case = Case(\n",
    "        base_dir=base_dir,\n",
    "        phi=phi,\n",
    "        lat_size=lat_size,\n",
    "        time_step=time_step,\n",
    "        post=post,\n",
    "    )\n",
    "    return field_path(case)\n",
    "\n",
    "def read_field_sorted(path: Path, var_name: str, sort_cols: list[str]) -> tuple[np.ndarray, np.ndarray]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file:\\n  {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    missing = [c for c in (sort_cols + [var_name]) if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path.name}: missing columns {missing}\")\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=sort_cols + [var_name])\n",
    "    df = df.sort_values(sort_cols, kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    coords = df[sort_cols].to_numpy(dtype=np.float64)\n",
    "    values = df[var_name].to_numpy(dtype=np.float64)\n",
    "    return coords, values\n",
    "\n",
    "def coords_match(a: np.ndarray, b: np.ndarray, atol: float) -> bool:\n",
    "    if a.shape != b.shape:\n",
    "        return False\n",
    "    if atol == 0.0:\n",
    "        return np.array_equal(a, b)\n",
    "    return np.allclose(a, b, atol=atol, rtol=0.0)\n",
    "\n",
    "# ----------------------------\n",
    "# Build X_points: (n_points_cropped, n_snaps)\n",
    "# ----------------------------\n",
    "times = list(range(TIME_STEP_START, TIME_STEP_END + 1))\n",
    "\n",
    "ref_path = field_csv_path(BASE_DIR, PHI, LAT_SIZE, times[0], POST)\n",
    "coords_ref_full, snap0_full = read_field_sorted(ref_path, VAR_NAME, SORT_COLS)\n",
    "\n",
    "mask_x = coords_ref_full[:, 0] > X_THESHOLD\n",
    "coords_ref = coords_ref_full[mask_x]\n",
    "snap0 = snap0_full[mask_x]\n",
    "\n",
    "snapshots = [snap0]\n",
    "for t in times[1:]:\n",
    "    p = field_csv_path(BASE_DIR, PHI, LAT_SIZE, t, POST)\n",
    "    coords_t_full, snap_t_full = read_field_sorted(p, VAR_NAME, SORT_COLS)\n",
    "\n",
    "    if coords_t_full.shape[0] != coords_ref_full.shape[0]:\n",
    "        raise ValueError(f\"Full point count changed at t={t}.\")\n",
    "\n",
    "    if not coords_match(coords_t_full, coords_ref_full, COORD_TOL):\n",
    "        raise ValueError(f\"Full coordinates mismatch at t={t} (sorting/mesh changed).\")\n",
    "\n",
    "    snapshots.append(snap_t_full[mask_x])\n",
    "\n",
    "X_points = np.stack(snapshots, axis=1).astype(np.float64)  # (N, T)\n",
    "N, T_total = X_points.shape\n",
    "\n",
    "print(f\"Read {T_total} snapshots with N={N} cropped points (x>{X_THESHOLD}).\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from flamekit.io_fields import field_path\n",
    "from flamekit.io_fronts import Case\n",
    "# ============================================================\n",
    "# BOX 2/3 — Train a local Graph-CNN (kNN message passing) to predict next step\n",
    "#          NO grid interpolation; neighborhoods are defined on (x,y) points.\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# ----------------------------\n",
    "# TRAINING SETTINGS\n",
    "# ----------------------------\n",
    "DEVICE = \"cuda\"\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE == \"cuda\" and not torch.cuda.is_available():\n",
    "    DEVICE = \"cpu\"\n",
    "device = torch.device(DEVICE)\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "KNN_K = 12                 # number of neighbors per point (excluding self)\n",
    "LAYERS = 4                 # graph conv layers\n",
    "WIDTH = 64                 # hidden channels\n",
    "EPOCHS = 300\n",
    "BATCH_TIMES = 4            # number of (t -> t+1) pairs per gradient step\n",
    "STEPS_PER_EPOCH = 50\n",
    "LR = 2e-3\n",
    "WEIGHT_DECAY = 1e-8\n",
    "\n",
    "# If N is large, you may need smaller WIDTH, smaller KNN_K, and BATCH_TIMES=1..2.\n",
    "\n",
    "# ----------------------------\n",
    "# Build kNN graph once (CPU), then move indices to GPU\n",
    "# ----------------------------\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "coords = coords_ref.astype(np.float64)\n",
    "nbrs = NearestNeighbors(n_neighbors=KNN_K + 1, algorithm=\"auto\").fit(coords)\n",
    "dist, idx = nbrs.kneighbors(coords)  # idx: (N, K+1), includes self at column 0\n",
    "\n",
    "# drop self-neighbor\n",
    "nbr_idx = idx[:, 1:].astype(np.int64)                  # (N, K)\n",
    "nbr_dist = dist[:, 1:].astype(np.float32)              # (N, K)\n",
    "\n",
    "# optional distance-based weights (normalized)\n",
    "w = 1.0 / (nbr_dist + 1e-6)\n",
    "w = w / (w.sum(axis=1, keepdims=True) + 1e-12)         # (N,K)\n",
    "\n",
    "nbr_idx_t = torch.from_numpy(nbr_idx).to(device)\n",
    "w_t = torch.from_numpy(w).to(device)                   # (N,K)\n",
    "\n",
    "# ----------------------------\n",
    "# Data tensors (time as batch)\n",
    "# ----------------------------\n",
    "# X_points: (N,T). We train on pairs (t -> t+1).\n",
    "X_seq = X_points.T.astype(np.float32)  # (T,N)\n",
    "\n",
    "# Normalize per-point over time (helps stability)\n",
    "mu = X_seq.mean(axis=0, keepdims=True)\n",
    "sd = X_seq.std(axis=0, keepdims=True) + 1e-6\n",
    "Xn_seq = (X_seq - mu) / sd             # (T,N)\n",
    "\n",
    "Xn_t = torch.from_numpy(Xn_seq).to(device)  # (T,N)\n",
    "\n",
    "# ----------------------------\n",
    "# Graph-CNN layers (message passing)\n",
    "# ----------------------------\n",
    "class GraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple GraphSAGE-style conv:\n",
    "      m_i = mean_j (h_j) and max_j(h_j) over kNN\n",
    "      optionally weighted mean via w\n",
    "      h'_i = MLP([h_i, mean, max])\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in: int, c_out: int) -> None:\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(3 * c_in, c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(c_out, c_out),\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(c_out)\n",
    "\n",
    "    def forward(self, h: torch.Tensor, nbr_idx: torch.Tensor, w: torch.Tensor) -> torch.Tensor:\n",
    "        # h: (B,N,C)\n",
    "        # nbr_idx: (N,K)\n",
    "        # w: (N,K)\n",
    "        B, N, C = h.shape\n",
    "        # gather neighbors: (B,N,K,C)\n",
    "        h_nei = h[:, nbr_idx, :]  # advanced indexing; nbr_idx is (N,K)\n",
    "\n",
    "        # weighted mean: sum_k w * h_nei\n",
    "        w_ = w.unsqueeze(0).unsqueeze(-1)  # (1,N,K,1)\n",
    "        mean = (w_ * h_nei).sum(dim=2)     # (B,N,C)\n",
    "\n",
    "        mx = h_nei.max(dim=2).values       # (B,N,C)\n",
    "\n",
    "        x = torch.cat([h, mean, mx], dim=-1)   # (B,N,3C)\n",
    "        out = self.mlp(x)\n",
    "        out = self.norm(out)\n",
    "        return out\n",
    "\n",
    "class GraphCNNNextStep(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: u(t) as scalar per point.\n",
    "    Output: u(t+1) scalar per point.\n",
    "    \"\"\"\n",
    "    def __init__(self, width: int, layers: int) -> None:\n",
    "        super().__init__()\n",
    "        self.in_lin = nn.Linear(1, width)\n",
    "\n",
    "        self.convs = nn.ModuleList([GraphConv(width, width) for _ in range(layers)])\n",
    "        self.out_lin = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(width, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, u: torch.Tensor, nbr_idx: torch.Tensor, w: torch.Tensor) -> torch.Tensor:\n",
    "        # u: (B,N) -> (B,N,1)\n",
    "        h = self.in_lin(u.unsqueeze(-1))  # (B,N,width)\n",
    "        for conv in self.convs:\n",
    "            h_new = conv(h, nbr_idx, w)\n",
    "            h = h + h_new  # residual\n",
    "        y = self.out_lin(h).squeeze(-1)   # (B,N)\n",
    "        return y\n",
    "\n",
    "model = GraphCNNNextStep(width=WIDTH, layers=LAYERS).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# ----------------------------\n",
    "# Train\n",
    "# ----------------------------\n",
    "model.train()\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    losses = []\n",
    "    for _ in range(STEPS_PER_EPOCH):\n",
    "        # sample random time indices for training pairs\n",
    "        t0 = np.random.randint(0, T_total - 1, size=BATCH_TIMES)\n",
    "        u0 = Xn_t[t0, :]           # (B,N)\n",
    "        u1 = Xn_t[t0 + 1, :]       # (B,N)\n",
    "\n",
    "        pred = model(u0, nbr_idx_t, w_t)\n",
    "        loss = loss_fn(pred, u1)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    if epoch == 1 or epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch:4d}/{EPOCHS} | train MSE (norm) = {float(np.mean(losses)):.3e}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Forecast next step from last snapshot\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "t_next = TIME_STEP_END + 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    u_last = Xn_t[-1:, :]                               # (1,N) normalized\n",
    "    u_next_pred_n = model(u_last, nbr_idx_t, w_t)[0]     # (N,) normalized\n",
    "\n",
    "# Undo normalization back to physical units\n",
    "u_next_pred = (u_next_pred_n.cpu().numpy() * sd.reshape(-1) + mu.reshape(-1)).astype(np.float64)  # (N,)\n",
    "\n",
    "# Save prediction\n",
    "out_dir = field_path(Case(base_dir=BASE_DIR, phi=PHI, lat_size=LAT_SIZE, time_step=0, post=POST)).parent\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out = pd.DataFrame(coords_ref, columns=SORT_COLS)\n",
    "out[f\"{VAR_NAME}_pred\"] = u_next_pred\n",
    "out_path = out_dir / f\"cnn_graph_pred_{VAR_NAME}_{t_next}_xgt{int(X_THESHOLD)}.csv\"\n",
    "out.to_csv(out_path, index=False)\n",
    "print(\"Wrote:\", out_path)\n"
   ],
   "id": "b91d21faa42c50d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# BOX 3/3 — Plotting: pred/true fields + errors + Ttrue vs Tpred\n",
    "# ============================================================\n",
    "path_true = field_csv_path(BASE_DIR, PHI, LAT_SIZE, t_next, POST)\n",
    "\n",
    "# Triangulation for spatial plots on the original point cloud\n",
    "x = coords_ref[:, 0].astype(float)\n",
    "y = coords_ref[:, 1].astype(float)\n",
    "tri = mtri.Triangulation(x, y)\n",
    "try:\n",
    "    analyzer = mtri.TriAnalyzer(tri)\n",
    "    tri.set_mask(analyzer.get_flat_tri_mask(min_circle_ratio=0.02))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "def tricontour_field(vals: np.ndarray, title: str, cbar_label: str, vmin=None, vmax=None) -> None:\n",
    "    fig = plt.figure(figsize=(7.2, 5.8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cf = ax.tricontourf(tri, vals, levels=60, vmin=vmin, vmax=vmax)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "    ax.set_title(title)\n",
    "    cbar = fig.colorbar(cf, ax=ax, orientation=\"horizontal\", pad=0.08, fraction=0.06)\n",
    "    cbar.set_label(cbar_label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if path_true.exists():\n",
    "    coords_true_full, snap_true_full = read_field_sorted(path_true, VAR_NAME, SORT_COLS)\n",
    "\n",
    "    if coords_true_full.shape[0] != coords_ref_full.shape[0]:\n",
    "        raise ValueError(\"True next-step has different full point count; cannot compare directly.\")\n",
    "\n",
    "    if not coords_match(coords_true_full, coords_ref_full, COORD_TOL):\n",
    "        raise ValueError(\"True next-step full coordinates changed; cannot compare directly.\")\n",
    "\n",
    "    u_true = snap_true_full[mask_x].astype(np.float64)\n",
    "\n",
    "    err = u_next_pred - u_true\n",
    "    abs_err = np.abs(err)\n",
    "\n",
    "    rmse = float(np.sqrt(np.mean(err**2)))\n",
    "    rel_l2 = float(np.linalg.norm(err) / (np.linalg.norm(u_true) + 1e-12))\n",
    "    print(f\"Next-step RMSE: {rmse:.6e}\")\n",
    "    print(f\"Next-step relative L2 error: {rel_l2:.6e}\")\n",
    "\n",
    "    # Save error CSV\n",
    "    out_err = pd.DataFrame(coords_ref, columns=SORT_COLS)\n",
    "    out_err[f\"{VAR_NAME}_true\"] = u_true\n",
    "    out_err[f\"{VAR_NAME}_pred\"] = u_next_pred\n",
    "    out_err[\"err\"] = err\n",
    "    out_err[\"abs_err\"] = abs_err\n",
    "    err_path = out_dir / f\"cnn_graph_err_{VAR_NAME}_{t_next}_xgt{int(X_THESHOLD)}.csv\"\n",
    "    out_err.to_csv(err_path, index=False)\n",
    "    print(\"Wrote:\", err_path)\n",
    "\n",
    "    # Shared color scale for true/pred fields\n",
    "    vmin = float(min(np.percentile(u_true, 0.5), np.percentile(u_next_pred, 0.5)))\n",
    "    vmax = float(max(np.percentile(u_true, 99.5), np.percentile(u_next_pred, 99.5)))\n",
    "\n",
    "    tricontour_field(\n",
    "        u_next_pred,\n",
    "        title=f\"{VAR_NAME} PRED (Graph-CNN) at t={t_next} (x > {X_THESHOLD})\",\n",
    "        cbar_label=f\"{VAR_NAME} (pred)\",\n",
    "        vmin=vmin, vmax=vmax,\n",
    "    )\n",
    "    tricontour_field(\n",
    "        u_true,\n",
    "        title=f\"{VAR_NAME} TRUE at t={t_next} (x > {X_THESHOLD})\",\n",
    "        cbar_label=f\"{VAR_NAME} (true)\",\n",
    "        vmin=vmin, vmax=vmax,\n",
    "    )\n",
    "\n",
    "    # Requested: Ttrue vs Tpred scatter\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(u_true, u_next_pred, s=2)\n",
    "    lo = float(min(u_true.min(), u_next_pred.min()))\n",
    "    hi = float(max(u_true.max(), u_next_pred.max()))\n",
    "    plt.plot([lo, hi], [lo, hi], linestyle=\"--\")\n",
    "    plt.xlabel(f\"{VAR_NAME}_true\")\n",
    "    plt.ylabel(f\"{VAR_NAME}_pred\")\n",
    "    plt.title(f\"{VAR_NAME}_true vs {VAR_NAME}_pred at t={t_next} (x > {X_THESHOLD})\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Error maps\n",
    "    vmax_signed = float(np.percentile(np.abs(err), 99.0)) + 1e-30\n",
    "    vmax_abs = float(np.percentile(abs_err, 99.0)) + 1e-30\n",
    "\n",
    "    tricontour_field(\n",
    "        err,\n",
    "        title=f\"{VAR_NAME} signed error (pred - true) at t={t_next} (x > {X_THESHOLD})\",\n",
    "        cbar_label=\"Signed error\",\n",
    "        vmin=-vmax_signed, vmax=vmax_signed,\n",
    "    )\n",
    "    tricontour_field(\n",
    "        abs_err,\n",
    "        title=f\"{VAR_NAME} absolute error |pred - true| at t={t_next} (x > {X_THESHOLD})\",\n",
    "        cbar_label=\"Absolute error\",\n",
    "        vmin=0.0, vmax=vmax_abs,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"True next-step file does not exist; plotting only prediction.\")\n",
    "    tricontour_field(\n",
    "        u_next_pred,\n",
    "        title=f\"{VAR_NAME} PRED (Graph-CNN) at t={t_next} (x > {X_THESHOLD})\",\n",
    "        cbar_label=f\"{VAR_NAME} (pred)\",\n",
    "    )\n"
   ],
   "id": "aeebe885aa1f5108"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}