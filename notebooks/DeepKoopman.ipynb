{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71da4d09",
   "metadata": {},
   "source": [
    "## Description:\n",
    "Learns a koopman operator for the time evolution of the flame field. It uses an autoencoder style of NN architecture to encode the data X into a latent space Z. It then learns a matrix which progresses the field to the next time step (Z_t+1 = K Z_t). It then decodes the prediction back to the original data space X_t+1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddeb16ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "import yaml\n",
    "\n",
    "from flamekit.io_fields import field_path\n",
    "from flamekit.io_fronts import Case\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from mpi4py import MPI\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as mtri\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256e99c43591db4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T16:09:01.161853Z",
     "start_time": "2025-12-24T15:51:16.442279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference timestep: 200\n",
      "X_THESHOLD=300.0 -> keeping 255744/839680 points\n",
      "n_points=255744, n_snapshots=11\n",
      "Reading: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/isocontours/phi0.40/h400x025_ref/extracted_field_post_200.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "CONFIG_PATH = PROJECT_ROOT / \"notebooks\" / \"configs\" / \"DeepKoopman.yaml\"\n",
    "CFG = yaml.safe_load(CONFIG_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# ----------------------------\n",
    "# USER SETTINGS (from YAML)\n",
    "# ----------------------------\n",
    "TIME_STEP_START = int(CFG[\"TIME_STEP_START\"])\n",
    "TIME_STEP_END = int(CFG[\"TIME_STEP_END\"])\n",
    "\n",
    "PHI = float(CFG[\"PHI\"])\n",
    "LAT_SIZE = str(CFG[\"LAT_SIZE\"])\n",
    "POST = bool(CFG[\"POST\"])\n",
    "\n",
    "BASE_DIR = PROJECT_ROOT / Path(CFG[\"BASE_DIR\"])\n",
    "VAR_NAME = str(CFG[\"VAR_NAME\"])\n",
    "SORT_COLS = list(CFG[\"SORT_COLS\"])\n",
    "COORD_TOL = float(CFG[\"COORD_TOL\"])\n",
    "\n",
    "CONTOUR_LEVELS_FILLED = int(CFG.get(\"CONTOUR_LEVELS_FILLED\", 60))\n",
    "\n",
    "X_THESHOLD = float(CFG[\"X_THESHOLD\"])  # keep only x > threshold\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def field_csv_path(base_dir: Path, phi: float, lat_size: str, time_step: int, post: bool) -> Path:\n",
    "    case = Case(\n",
    "        base_dir=base_dir,\n",
    "        phi=phi,\n",
    "        lat_size=lat_size,\n",
    "        time_step=time_step,\n",
    "        post=post,\n",
    "    )\n",
    "    return field_path(case)\n",
    "\n",
    "def read_field_sorted(path: Path, var_name: str, sort_cols: list[str]) -> tuple[np.ndarray, np.ndarray]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file:\\n  {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    missing = [c for c in (sort_cols + [var_name]) if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path.name}: missing columns {missing}\")\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=sort_cols + [var_name])\n",
    "    df = df.sort_values(sort_cols, kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    coords = df[sort_cols].to_numpy(dtype=np.float64)\n",
    "    values = df[var_name].to_numpy(dtype=np.float64)\n",
    "    return coords, values\n",
    "\n",
    "# ----------------------------\n",
    "# Build X: (n_points_cropped, n_snaps)\n",
    "# ----------------------------\n",
    "times = list(range(TIME_STEP_START, TIME_STEP_END + 1))\n",
    "\n",
    "ref_path = field_csv_path(BASE_DIR, PHI, LAT_SIZE, times[0], POST)\n",
    "coords_ref_full, snap0_full = read_field_sorted(ref_path, VAR_NAME, SORT_COLS)\n",
    "\n",
    "x_ref = coords_ref_full[:, 0]\n",
    "mask_x = x_ref > X_THESHOLD\n",
    "\n",
    "coords_ref = coords_ref_full[mask_x]\n",
    "snap0 = snap0_full[mask_x]\n",
    "\n",
    "n_points = coords_ref.shape[0]\n",
    "n_snaps = len(times)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"Reference timestep: {times[0]}\")\n",
    "    print(f\"X_THESHOLD={X_THESHOLD} -> keeping {n_points}/{coords_ref_full.shape[0]} points\")\n",
    "    print(f\"n_points={n_points}, n_snapshots={n_snaps}\")\n",
    "    print(f\"Reading: {ref_path}\")\n",
    "\n",
    "snapshots = [snap0]\n",
    "for t in times[1:]:\n",
    "    path = field_csv_path(BASE_DIR, PHI, LAT_SIZE, t, POST)\n",
    "    coords_t_full, snap_t_full = read_field_sorted(path, VAR_NAME, SORT_COLS)\n",
    "\n",
    "    if coords_t_full.shape[0] != coords_ref_full.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent n_points (full) at timestep {t}: {coords_t_full.shape[0]} vs {coords_ref_full.shape[0]}\"\n",
    "        )\n",
    "\n",
    "    if COORD_TOL == 0.0:\n",
    "        same = np.array_equal(coords_t_full, coords_ref_full)\n",
    "    else:\n",
    "        same = np.allclose(coords_t_full, coords_ref_full, atol=COORD_TOL, rtol=0.0)\n",
    "\n",
    "    if not same:\n",
    "        raise ValueError(\n",
    "            f\"Coordinates mismatch at timestep {t}.\\n\"\n",
    "            f\"Set COORD_TOL>0 or interpolate/regrid.\"\n",
    "        )\n",
    "\n",
    "    snap_t = snap_t_full[mask_x]\n",
    "    if snap_t.shape[0] != n_points:\n",
    "        raise RuntimeError(\"Masking produced inconsistent point count. Check X_THESHOLD and sorting.\")\n",
    "\n",
    "    snapshots.append(snap_t)\n",
    "\n",
    "X = np.stack(snapshots, axis=1).astype(np.float64)  # (n_points, n_snaps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615d43b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 4GB Laptop GPU\n",
      "PCA: n_components=11, explained_var_sum=1.0000\n",
      "Training DeepKoopman: x_dim=11, z_dim=32, T=11, rollout_len=3\n",
      "Epoch     1/400 | loss=7.473517e+04 | rho(K)=1.427643\n",
      "Epoch   100/400 | loss=3.898150e+03 | rho(K)=1.050462\n",
      "Epoch   200/400 | loss=1.946702e+01 | rho(K)=1.033978\n",
      "Epoch   300/400 | loss=8.372019e-04 | rho(K)=1.028048\n",
      "Epoch   400/400 | loss=9.486561e-05 | rho(K)=1.024943\n",
      "Wrote: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/isocontours/phi0.40/h400x025_ref/deepkoopman_pred_T_211_xgt300.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Deep Koopman settings\n",
    "DEVICE = str(CFG[\"DEVICE\"])\n",
    "DT = float(CFG[\"DT\"])\n",
    "\n",
    "DROPOUT = float(CFG[\"DROPOUT\"])\n",
    "\n",
    "OFFLOAD_MODEL_TO_CPU = bool(CFG[\"OFFLOAD_MODEL_TO_CPU\"])\n",
    "\n",
    "USE_PCA = bool(CFG[\"USE_PCA\"])\n",
    "PCA_DIM = int(CFG[\"PCA_DIM\"])\n",
    "\n",
    "Z_DIM = int(CFG[\"Z_DIM\"])\n",
    "ENC_HIDDEN = tuple(CFG[\"ENC_HIDDEN\"])\n",
    "DEC_HIDDEN = tuple(CFG[\"DEC_HIDDEN\"])\n",
    "\n",
    "EPOCHS = int(CFG[\"EPOCHS\"])\n",
    "BATCHES_PER_EPOCH = int(CFG[\"BATCHES_PER_EPOCH\"])\n",
    "BATCH_SIZE = int(CFG[\"BATCH_SIZE\"])\n",
    "ROLLOUT_LEN = int(CFG[\"ROLLOUT_LEN\"])\n",
    "\n",
    "LR = float(CFG[\"LR\"])\n",
    "WEIGHT_DECAY = float(CFG[\"WEIGHT_DECAY\"])\n",
    "\n",
    "W_RECON = float(CFG[\"W_RECON\"])\n",
    "W_PRED = float(CFG[\"W_PRED\"])\n",
    "W_LAT = float(CFG[\"W_LAT\"])\n",
    "W_STAB = float(CFG[\"W_STAB\"])\n",
    "\n",
    "SEED = int(CFG[\"SEED\"])\n",
    "# ----------------------------\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if DEVICE == \"cuda\" and not torch.cuda.is_available():\n",
    "    DEVICE = \"cpu\"\n",
    "device = torch.device(DEVICE)\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"Using device:\", device)\n",
    "    if device.type == \"cuda\":\n",
    "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "def optimizer_to(optimizer: optim.Optimizer, device: torch.device) -> None:\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.to(device)\n",
    "\n",
    "# Arrange as (T, n_points)\n",
    "X_seq = X.T.astype(np.float32)  # (T, n_points)\n",
    "\n",
    "# Normalize per spatial DOF over time\n",
    "X_mean = X_seq.mean(axis=0, keepdims=True)\n",
    "X_std  = X_seq.std(axis=0, keepdims=True) + 1e-6\n",
    "Xn_seq = (X_seq - X_mean) / X_std\n",
    "\n",
    "# Optional PCA\n",
    "if USE_PCA:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca_ncomp = int(min(PCA_DIM, Xn_seq.shape[0], Xn_seq.shape[1]))\n",
    "    if pca_ncomp < 1:\n",
    "        raise ValueError(\"PCA_DIM too small after min(PCA_DIM, n_snaps, n_points).\")\n",
    "    pca = PCA(n_components=pca_ncomp, svd_solver=\"randomized\", random_state=SEED)\n",
    "    Xp_seq = pca.fit_transform(Xn_seq)  # (T, pca_dim)\n",
    "    if rank == 0:\n",
    "        evr = float(np.sum(pca.explained_variance_ratio_))\n",
    "        print(f\"PCA: n_components={pca_ncomp}, explained_var_sum={evr:.4f}\")\n",
    "else:\n",
    "    pca = None\n",
    "    Xp_seq = Xn_seq\n",
    "\n",
    "x_dim = Xp_seq.shape[1]\n",
    "T_total = Xp_seq.shape[0]\n",
    "if ROLLOUT_LEN >= T_total:\n",
    "    raise ValueError(f\"ROLLOUT_LEN={ROLLOUT_LEN} must be < number of snapshots T={T_total}.\")\n",
    "\n",
    "Xp_torch = torch.from_numpy(Xp_seq)  # keep on CPU; move batches to GPU\n",
    "\n",
    "def build_mlp(in_dim: int, hidden: tuple[int, ...], out_dim: int, dropout: float) -> nn.Sequential:\n",
    "    layers: list[nn.Module] = []\n",
    "    prev = in_dim\n",
    "    for h in hidden:\n",
    "        layers.append(nn.Linear(prev, h))\n",
    "        layers.append(nn.Tanh())\n",
    "        if dropout > 0.0:\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "        prev = h\n",
    "    layers.append(nn.Linear(prev, out_dim))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class DeepKoopman(nn.Module):\n",
    "    def __init__(self, x_dim: int, z_dim: int, enc_hidden: tuple[int, ...], dec_hidden: tuple[int, ...]) -> None:\n",
    "        super().__init__()\n",
    "        self.enc = build_mlp(x_dim, enc_hidden, z_dim, DROPOUT)\n",
    "        self.dec = build_mlp(z_dim, dec_hidden, x_dim, DROPOUT)\n",
    "        self.K = nn.Parameter(torch.eye(z_dim))  # linear Koopman operator\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.enc(x)\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.dec(z)\n",
    "\n",
    "    def step_latent(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return z @ self.K.T\n",
    "\n",
    "def spectral_radius(K: torch.Tensor) -> torch.Tensor:\n",
    "    eigvals = torch.linalg.eigvals(K)\n",
    "    return torch.max(torch.abs(eigvals)).real\n",
    "\n",
    "def sample_batch_indices(T: int, rollout_len: int, batch_size: int) -> list[int]:\n",
    "    max_start = T - (rollout_len + 1)\n",
    "    if max_start < 0:\n",
    "        raise ValueError(f\"Not enough snapshots: T={T}, rollout_len={rollout_len}\")\n",
    "    return np.random.randint(0, max_start + 1, size=batch_size).tolist()\n",
    "\n",
    "def make_batch(Xp_seq_torch: torch.Tensor, idx0: list[int], rollout_len: int) -> torch.Tensor:\n",
    "    seqs = [Xp_seq_torch[i : i + rollout_len + 1] for i in idx0]\n",
    "    return torch.stack(seqs, dim=0)  # (B, L+1, x_dim)\n",
    "\n",
    "model = DeepKoopman(x_dim=x_dim, z_dim=Z_DIM, enc_hidden=ENC_HIDDEN, dec_hidden=DEC_HIDDEN).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"Training DeepKoopman: x_dim={x_dim}, z_dim={Z_DIM}, T={T_total}, rollout_len={ROLLOUT_LEN}\")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for _ in range(BATCHES_PER_EPOCH):\n",
    "        idx0 = sample_batch_indices(T_total, ROLLOUT_LEN, batch_size=BATCH_SIZE)\n",
    "        Xb = make_batch(Xp_torch, idx0, ROLLOUT_LEN).to(device)  # (B, L+1, x_dim)\n",
    "\n",
    "        B, Lp1, _ = Xb.shape\n",
    "        L = Lp1 - 1\n",
    "\n",
    "        z_true = model.encode(Xb.reshape(B * (L + 1), x_dim)).reshape(B, L + 1, Z_DIM)\n",
    "\n",
    "        # Recon\n",
    "        X_recon = model.decode(z_true.reshape(B * (L + 1), Z_DIM)).reshape(B, L + 1, x_dim)\n",
    "        loss_recon = mse(X_recon, Xb)\n",
    "\n",
    "        # Latent rollout from z0\n",
    "        z_list = [z_true[:, 0, :]]\n",
    "        for _k in range(L):\n",
    "            z_list.append(model.step_latent(z_list[-1]))\n",
    "        z_pred = torch.stack(z_list, dim=1)  # (B, L+1, Z_DIM)\n",
    "\n",
    "        X_pred = model.decode(z_pred.reshape(B * (L + 1), Z_DIM)).reshape(B, L + 1, x_dim)\n",
    "\n",
    "        loss_pred = mse(X_pred[:, 1:, :], Xb[:, 1:, :])\n",
    "        loss_lat  = mse(z_pred[:, 1:, :], z_true[:, 1:, :])\n",
    "\n",
    "        rho = spectral_radius(model.K)\n",
    "        loss_stab = torch.relu(rho - 1.0) ** 2\n",
    "\n",
    "        loss = W_RECON * loss_recon + W_PRED * loss_pred + W_LAT * loss_lat + W_STAB * loss_stab\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Release batch tensors explicitly to free GPU memory\n",
    "        del Xb, z_true, z_list, X_recon, z_pred, X_pred, loss_recon, loss_pred, loss_lat, loss_stab, loss, rho\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if rank == 0 and (epoch == 1 or epoch % 100 == 0):\n",
    "        avg = float(np.mean(losses)) if losses else float(\"nan\")\n",
    "        with torch.no_grad():\n",
    "            rho_val = float(spectral_radius(model.K).cpu().item())\n",
    "        print(f\"Epoch {epoch:5d}/{EPOCHS} | loss={avg:.6e} | rho(K)={rho_val:.6f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# One-step forecast at next timestep\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "t_next = times[-1] + 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_last = Xp_torch[-1, :].unsqueeze(0).to(device)  # (1, x_dim)\n",
    "    z_last = model.encode(x_last)          # (1, z_dim)\n",
    "    z_next = model.step_latent(z_last)     # (1, z_dim)\n",
    "    x_next_p = model.decode(z_next).cpu().numpy()[0]  # (x_dim,)\n",
    "\n",
    "# Free inference tensors and optionally move model off GPU\n",
    "del x_last, z_last, z_next\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if OFFLOAD_MODEL_TO_CPU and device.type == \"cuda\":\n",
    "    model.to(\"cpu\")\n",
    "    optimizer_to(opt, torch.device(\"cpu\"))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Undo PCA + normalization\n",
    "if USE_PCA:\n",
    "    x_next_norm = pca.inverse_transform(x_next_p.reshape(1, -1))[0]\n",
    "else:\n",
    "    x_next_norm = x_next_p\n",
    "\n",
    "x_next_pred = (x_next_norm * X_std.reshape(-1) + X_mean.reshape(-1)).astype(np.float64)  # (n_points,)\n",
    "\n",
    "# Save prediction\n",
    "out_dir = field_path(Case(base_dir=BASE_DIR, phi=PHI, lat_size=LAT_SIZE, time_step=0, post=POST)).parent\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out = pd.DataFrame(coords_ref, columns=SORT_COLS)\n",
    "out[f\"{VAR_NAME}_pred\"] = x_next_pred\n",
    "out_path = out_dir / f\"deepkoopman_pred_{VAR_NAME}_{t_next}_xgt{int(X_THESHOLD)}.csv\"\n",
    "out.to_csv(out_path, index=False)\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"Wrote:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b801ba0fd65ae017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T17:29:59.967676Z",
     "start_time": "2025-12-24T17:29:42.787455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/prediction.png\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/prediction.pdf\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/prediction.svg\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/true_prev.png\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/true_prev.pdf\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/true_prev.svg\n",
      "Next-step compare at t=211: RMSE=3.523926e-01, relL2=9.527633e-02\n",
      "Wrote: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/isocontours/phi0.40/h400x025_ref/deepkoopman_err_T_211_xgt300.csv\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/true.png\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/true.pdf\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/true.svg\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/predvstruth.png\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/predvstruth.pdf\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/predvstruth.svg\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/error.png\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/error.pdf\n",
      "Saved: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/Koopman/error.svg\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BOX 3/3 â€” Plotting + comparison + error maps + saving (NO TITLES)\n",
    "#   Saves:\n",
    "#     prediction.png, true.png, predvstruth.png, error.png\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ---------- where to save figures ----------\n",
    "FIG_DIR = PROJECT_ROOT / Path(CFG[\"FIG_DIR\"])\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ---------- plot style (match DMD) ----------\n",
    "PLOT_FONT_FAMILY = \"Courier New\"\n",
    "PLOT_FONT_SIZE = 20\n",
    "FIG_DPI = 250\n",
    "LINE_WIDTH = 2.2\n",
    "\n",
    "COLOR_DATA = \"#77b5b6\"\n",
    "COLOR_DATA_EDGE = \"#378d94\"\n",
    "COLOR_PRED = \"#9671bd\"\n",
    "COLOR_PRED_EDGE = \"#6a408d\"\n",
    "COLOR_NEUTRAL = \"#7e7e7e\"\n",
    "COLOR_LINE = \"#8a8a8a\"\n",
    "\n",
    "def apply_plot_style() -> None:\n",
    "    plt.rcParams.update({\n",
    "        \"font.family\": PLOT_FONT_FAMILY,\n",
    "        \"font.size\": PLOT_FONT_SIZE,\n",
    "        \"axes.titlesize\": PLOT_FONT_SIZE,\n",
    "        \"axes.labelsize\": PLOT_FONT_SIZE,\n",
    "        \"xtick.labelsize\": PLOT_FONT_SIZE,\n",
    "        \"ytick.labelsize\": PLOT_FONT_SIZE,\n",
    "        \"legend.fontsize\": PLOT_FONT_SIZE,\n",
    "        \"figure.titlesize\": PLOT_FONT_SIZE,\n",
    "        \"axes.linewidth\": 1.2,\n",
    "    })\n",
    "\n",
    "apply_plot_style()\n",
    "\n",
    "def style_colorbar(cbar, *, nbins: int = 5) -> None:\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    cbar.ax.tick_params(labelsize=PLOT_FONT_SIZE - 6)\n",
    "    cbar.locator = MaxNLocator(nbins=nbins)\n",
    "    cbar.update_ticks()\n",
    "\n",
    "def style_axes(ax) -> None:\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(True, which=\"major\", linestyle=\"-\", linewidth=0.75, alpha=0.25)\n",
    "    ax.grid(True, which=\"minor\", linestyle=\"-\", linewidth=0.25, alpha=0.15)\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", direction=\"in\", top=True, right=True)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", length=6, width=1.0)\n",
    "    ax.tick_params(axis=\"both\", which=\"minor\", length=3, width=0.8)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.2)\n",
    "\n",
    "# ---------- build triangulation from coords_ref ----------\n",
    "x_xy = coords_ref[:, 0].astype(float)\n",
    "y_xy = coords_ref[:, 1].astype(float)\n",
    "triang = mtri.Triangulation(x_xy, y_xy)\n",
    "try:\n",
    "    analyzer = mtri.TriAnalyzer(triang)\n",
    "    triang.set_mask(analyzer.get_flat_tri_mask(min_circle_ratio=0.02))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "def save_plot(fig, fname, dpi=FIG_DPI):\n",
    "    stem = Path(fname).stem\n",
    "    out_png = FIG_DIR / f\"{stem}.png\"\n",
    "    out_pdf = FIG_DIR / f\"{stem}.pdf\"\n",
    "    out_svg = FIG_DIR / f\"{stem}.svg\"\n",
    "\n",
    "    fig.savefig(out_png, dpi=dpi)\n",
    "    fig.savefig(out_pdf)\n",
    "    fig.savefig(out_svg)\n",
    "\n",
    "    print(\"Saved:\", out_png)\n",
    "    print(\"Saved:\", out_pdf)\n",
    "    print(\"Saved:\", out_svg)\n",
    "\n",
    "def save_tricontour_field(vals, fname, cbar_label, vmin=None, vmax=None, dpi=FIG_DPI):\n",
    "    fig = plt.figure(figsize=(7.2, 5.8), dpi=dpi, constrained_layout=True)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    cf = ax.tricontourf(triang, vals, levels=CONTOUR_LEVELS_FILLED, vmin=vmin, vmax=vmax)\n",
    "    style_axes(ax)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    # no title\n",
    "\n",
    "    cbar = fig.colorbar(cf, ax=ax, orientation=\"horizontal\", pad=0.08, fraction=0.06)\n",
    "    cbar.set_label(cbar_label)\n",
    "    style_colorbar(cbar)\n",
    "\n",
    "    save_plot(fig, fname, dpi=dpi)\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_scatter_true_vs_pred(true_vals, pred_vals, fname=\"predvstruth.png\", dpi=FIG_DPI):\n",
    "    fig = plt.figure(figsize=(5, 5), dpi=dpi, constrained_layout=True)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.scatter(true_vals, pred_vals, s=2, color=COLOR_DATA, edgecolors=COLOR_DATA_EDGE, linewidths=0.3)\n",
    "    lo = float(min(true_vals.min(), pred_vals.min()))\n",
    "    hi = float(max(true_vals.max(), pred_vals.max()))\n",
    "    ax.plot([lo, hi], [lo, hi], linestyle=\"--\", color=COLOR_LINE, linewidth=LINE_WIDTH)\n",
    "\n",
    "    ax.set_xlabel(f\"{VAR_NAME}_true\")\n",
    "    ax.set_ylabel(f\"{VAR_NAME}_pred\")\n",
    "    # no title\n",
    "    style_axes(ax)\n",
    "\n",
    "    save_plot(fig, fname, dpi=dpi)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------- always save prediction ----------\n",
    "vmin_pred = float(np.percentile(x_next_pred, 0.5))\n",
    "vmax_pred = float(np.percentile(x_next_pred, 99.5))\n",
    "save_tricontour_field(\n",
    "    x_next_pred,\n",
    "    fname=\"prediction.png\",\n",
    "    cbar_label=f\"{VAR_NAME} (pred)\",\n",
    "    vmin=vmin_pred,\n",
    "    vmax=vmax_pred,\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- save TRUE at previous timestep (t_prev) ----------\n",
    "t_prev = times[-1]\n",
    "path_prev = field_csv_path(BASE_DIR, PHI, LAT_SIZE, t_prev, POST)\n",
    "\n",
    "if path_prev.exists():\n",
    "    coords_prev_full, snap_prev_full = read_field_sorted(path_prev, VAR_NAME, SORT_COLS)\n",
    "\n",
    "    if coords_prev_full.shape[0] != coords_ref_full.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"True prev-step has different full point count: {coords_prev_full.shape[0]} vs {coords_ref_full.shape[0]}\"\n",
    "        )\n",
    "\n",
    "    if COORD_TOL == 0.0:\n",
    "        same = np.array_equal(coords_prev_full, coords_ref_full)\n",
    "    else:\n",
    "        same = np.allclose(coords_prev_full, coords_ref_full, atol=COORD_TOL, rtol=0.0)\n",
    "\n",
    "    if not same:\n",
    "        raise ValueError(\"True prev-step coordinates do not match reference coordinates.\")\n",
    "\n",
    "    snap_prev = snap_prev_full[mask_x].astype(np.float64)\n",
    "\n",
    "    vmin_prev = float(np.percentile(snap_prev, 0.5))\n",
    "    vmax_prev = float(np.percentile(snap_prev, 99.5))\n",
    "    save_tricontour_field(\n",
    "        snap_prev,\n",
    "        fname=\"true_prev.png\",\n",
    "        cbar_label=f\"{VAR_NAME} (true, prev)\",\n",
    "        vmin=vmin_prev,\n",
    "        vmax=vmax_prev,\n",
    "    )\n",
    "else:\n",
    "    print(\"True prev-step file does not exist; true_prev.png not saved.\")\n",
    "\n",
    "# ---------- load TRUE (if exists), then save true + scatter + abs error ----------\n",
    "path_true = field_csv_path(BASE_DIR, PHI, LAT_SIZE, t_next, POST)\n",
    "\n",
    "if path_true.exists():\n",
    "    coords_true_full, snap_true_full = read_field_sorted(path_true, VAR_NAME, SORT_COLS)\n",
    "\n",
    "    # Full coordinate check first\n",
    "    if coords_true_full.shape[0] != coords_ref_full.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"True next-step has different full point count: {coords_true_full.shape[0]} vs {coords_ref_full.shape[0]}\"\n",
    "        )\n",
    "\n",
    "    if COORD_TOL == 0.0:\n",
    "        same = np.array_equal(coords_true_full, coords_ref_full)\n",
    "    else:\n",
    "        same = np.allclose(coords_true_full, coords_ref_full, atol=COORD_TOL, rtol=0.0)\n",
    "\n",
    "    if not same:\n",
    "        raise ValueError(\"True next-step coordinates do not match reference coordinates.\")\n",
    "\n",
    "    snap_true = snap_true_full[mask_x].astype(np.float64)\n",
    "\n",
    "    # metrics\n",
    "    err = x_next_pred - snap_true\n",
    "    abs_err = np.abs(err)\n",
    "    rmse = float(np.sqrt(np.mean(err**2)))\n",
    "    rel_l2 = float(np.linalg.norm(err) / (np.linalg.norm(snap_true) + 1e-12))\n",
    "    print(f\"Next-step compare at t={t_next}: RMSE={rmse:.6e}, relL2={rel_l2:.6e}\")\n",
    "\n",
    "    # save error CSV (optional)\n",
    "    out_err = pd.DataFrame(coords_ref, columns=SORT_COLS)\n",
    "    out_err[f\"{VAR_NAME}_true\"] = snap_true\n",
    "    out_err[f\"{VAR_NAME}_pred\"] = x_next_pred\n",
    "    out_err[\"err\"] = err\n",
    "    out_err[\"abs_err\"] = abs_err\n",
    "    err_path = out_dir / f\"deepkoopman_err_{VAR_NAME}_{t_next}_xgt{int(X_THESHOLD)}.csv\"\n",
    "    out_err.to_csv(err_path, index=False)\n",
    "    print(\"Wrote:\", err_path)\n",
    "\n",
    "    # shared color scale for true/pred visuals\n",
    "    vmin_shared = float(min(np.percentile(snap_true, 0.5), np.percentile(x_next_pred, 0.5)))\n",
    "    vmax_shared = float(max(np.percentile(snap_true, 99.5), np.percentile(x_next_pred, 99.5)))\n",
    "\n",
    "    save_tricontour_field(\n",
    "        snap_true,\n",
    "        fname=\"true.png\",\n",
    "        cbar_label=f\"{VAR_NAME} (true)\",\n",
    "        vmin=vmin_shared,\n",
    "        vmax=vmax_shared,\n",
    "    )\n",
    "\n",
    "    save_scatter_true_vs_pred(\n",
    "        true_vals=snap_true,\n",
    "        pred_vals=x_next_pred,\n",
    "        fname=\"predvstruth.png\",\n",
    "    )\n",
    "\n",
    "    vmax_abs = float(np.percentile(abs_err, 99.0)) + 1e-30\n",
    "    save_tricontour_field(\n",
    "        abs_err,\n",
    "        fname=\"error.png\",\n",
    "        cbar_label=\"Absolute error\",\n",
    "        vmin=0.0,\n",
    "        vmax=vmax_abs,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"True next-step file does not exist; only prediction.png was saved.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93c188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429fcfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myproject)",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
