{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T16:09:01.161853Z",
     "start_time": "2025-12-24T15:51:16.442279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# BOX 1/3 — Reading files + building X (cropped consistently)\n",
    "# ============================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Optional MPI (safe in serial)\n",
    "try:\n",
    "    from mpi4py import MPI\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.rank\n",
    "except Exception:\n",
    "    comm = None\n",
    "    rank = 0\n",
    "\n",
    "# ----------------------------\n",
    "# USER SETTINGS\n",
    "# ----------------------------\n",
    "TIME_STEP_START = 200\n",
    "TIME_STEP_END   = 300\n",
    "\n",
    "PHI      = 0.40\n",
    "LAT_SIZE = \"025\"\n",
    "POST     = True\n",
    "\n",
    "BASE_DIR  = Path(\"../isocontours\")\n",
    "VAR_NAME  = \"T\"\n",
    "SORT_COLS = [\"x\", \"y\"]\n",
    "COORD_TOL = 0.0\n",
    "\n",
    "X_THESHOLD = 300  # keep only x > threshold\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def _case_suffix(phi: float, lat_size: str) -> str:\n",
    "    return f\"h400x{lat_size}_ref\"\n",
    "\n",
    "def field_csv_path(base_dir: Path, phi: float, lat_size: str, time_step: int, post: bool) -> Path:\n",
    "    suffix = _case_suffix(phi, lat_size)\n",
    "    folder = base_dir / f\"phi{phi:.2f}\" / suffix\n",
    "    fname = f\"extracted_field_post_{time_step}.csv\" if post else f\"extracted_field_{time_step}.csv\"\n",
    "    return folder / fname\n",
    "\n",
    "def read_field_sorted(path: Path, var_name: str, sort_cols: list[str]) -> tuple[np.ndarray, np.ndarray]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file:\\n  {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    missing = [c for c in (sort_cols + [var_name]) if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{path.name}: missing columns {missing}\")\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=sort_cols + [var_name])\n",
    "    df = df.sort_values(sort_cols, kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    coords = df[sort_cols].to_numpy(dtype=np.float64)\n",
    "    values = df[var_name].to_numpy(dtype=np.float64)\n",
    "    return coords, values\n",
    "\n",
    "# ----------------------------\n",
    "# Build X: (n_points_cropped, n_snaps)\n",
    "# ----------------------------\n",
    "times = list(range(TIME_STEP_START, TIME_STEP_END + 1))\n",
    "\n",
    "ref_path = field_csv_path(BASE_DIR, PHI, LAT_SIZE, times[0], POST)\n",
    "coords_ref_full, snap0_full = read_field_sorted(ref_path, VAR_NAME, SORT_COLS)\n",
    "\n",
    "x_ref = coords_ref_full[:, 0]\n",
    "mask_x = x_ref > X_THESHOLD\n",
    "\n",
    "coords_ref = coords_ref_full[mask_x]\n",
    "snap0 = snap0_full[mask_x]\n",
    "\n",
    "n_points = coords_ref.shape[0]\n",
    "n_snaps = len(times)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"Reference timestep: {times[0]}\")\n",
    "    print(f\"X_THESHOLD={X_THESHOLD} -> keeping {n_points}/{coords_ref_full.shape[0]} points\")\n",
    "    print(f\"n_points={n_points}, n_snapshots={n_snaps}\")\n",
    "    print(f\"Reading: {ref_path}\")\n",
    "\n",
    "snapshots = [snap0]\n",
    "for t in times[1:]:\n",
    "    path = field_csv_path(BASE_DIR, PHI, LAT_SIZE, t, POST)\n",
    "    coords_t_full, snap_t_full = read_field_sorted(path, VAR_NAME, SORT_COLS)\n",
    "\n",
    "    if coords_t_full.shape[0] != coords_ref_full.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"Inconsistent n_points (full) at timestep {t}: {coords_t_full.shape[0]} vs {coords_ref_full.shape[0]}\"\n",
    "        )\n",
    "\n",
    "    if COORD_TOL == 0.0:\n",
    "        same = np.array_equal(coords_t_full, coords_ref_full)\n",
    "    else:\n",
    "        same = np.allclose(coords_t_full, coords_ref_full, atol=COORD_TOL, rtol=0.0)\n",
    "\n",
    "    if not same:\n",
    "        raise ValueError(\n",
    "            f\"Coordinates mismatch at timestep {t}.\\n\"\n",
    "            f\"Set COORD_TOL>0 or interpolate/regrid.\"\n",
    "        )\n",
    "\n",
    "    snap_t = snap_t_full[mask_x]\n",
    "    if snap_t.shape[0] != n_points:\n",
    "        raise RuntimeError(\"Masking produced inconsistent point count. Check X_THESHOLD and sorting.\")\n",
    "\n",
    "    snapshots.append(snap_t)\n",
    "\n",
    "X = np.stack(snapshots, axis=1).astype(np.float64)  # (n_points, n_snaps)\n"
   ],
   "id": "256e99c43591db4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference timestep: 200\n",
      "X_THESHOLD=300 -> keeping 255744/839680 points\n",
      "n_points=255744, n_snapshots=101\n",
      "Reading: ..\\isocontours\\phi0.40\\h400x025_ref\\extracted_field_post_200.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T17:14:02.478198Z",
     "start_time": "2025-12-24T16:34:01.042111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# BOX 2/3 — Running DeepKoopman (AE + linear latent operator)\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ----------------------------\n",
    "# Deep Koopman settings\n",
    "# ----------------------------\n",
    "DEVICE = \"cuda\"\n",
    "DT = 1.0\n",
    "\n",
    "USE_PCA = True\n",
    "PCA_DIM = 24\n",
    "\n",
    "Z_DIM = 16\n",
    "ENC_HIDDEN = (256,)\n",
    "DEC_HIDDEN = (256,)\n",
    "\n",
    "EPOCHS = 3000\n",
    "BATCHES_PER_EPOCH = 50\n",
    "BATCH_SIZE = 16\n",
    "ROLLOUT_LEN = 10\n",
    "\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-7\n",
    "\n",
    "W_RECON = 1.0\n",
    "W_PRED  = 1.0\n",
    "W_LAT   = 0.1\n",
    "W_STAB  = 1e-3\n",
    "\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if DEVICE == \"cuda\" and not torch.cuda.is_available():\n",
    "    DEVICE = \"cpu\"\n",
    "device = torch.device(DEVICE)\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"Using device:\", device)\n",
    "    if device.type == \"cuda\":\n",
    "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Arrange as (T, n_points)\n",
    "X_seq = X.T.astype(np.float32)  # (T, n_points)\n",
    "\n",
    "# Normalize per spatial DOF over time\n",
    "X_mean = X_seq.mean(axis=0, keepdims=True)\n",
    "X_std  = X_seq.std(axis=0, keepdims=True) + 1e-6\n",
    "Xn_seq = (X_seq - X_mean) / X_std\n",
    "\n",
    "# Optional PCA\n",
    "if USE_PCA:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca_ncomp = int(min(PCA_DIM, Xn_seq.shape[0], Xn_seq.shape[1]))\n",
    "    if pca_ncomp < 1:\n",
    "        raise ValueError(\"PCA_DIM too small after min(PCA_DIM, n_snaps, n_points).\")\n",
    "    pca = PCA(n_components=pca_ncomp, svd_solver=\"randomized\", random_state=SEED)\n",
    "    Xp_seq = pca.fit_transform(Xn_seq)  # (T, pca_dim)\n",
    "    if rank == 0:\n",
    "        evr = float(np.sum(pca.explained_variance_ratio_))\n",
    "        print(f\"PCA: n_components={pca_ncomp}, explained_var_sum={evr:.4f}\")\n",
    "else:\n",
    "    pca = None\n",
    "    Xp_seq = Xn_seq\n",
    "\n",
    "x_dim = Xp_seq.shape[1]\n",
    "T_total = Xp_seq.shape[0]\n",
    "if ROLLOUT_LEN >= T_total:\n",
    "    raise ValueError(f\"ROLLOUT_LEN={ROLLOUT_LEN} must be < number of snapshots T={T_total}.\")\n",
    "\n",
    "Xp_torch = torch.from_numpy(Xp_seq).to(device)\n",
    "\n",
    "def build_mlp(in_dim: int, hidden: tuple[int, ...], out_dim: int) -> nn.Sequential:\n",
    "    layers: list[nn.Module] = []\n",
    "    prev = in_dim\n",
    "    for h in hidden:\n",
    "        layers.append(nn.Linear(prev, h))\n",
    "        layers.append(nn.Tanh())\n",
    "        prev = h\n",
    "    layers.append(nn.Linear(prev, out_dim))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class DeepKoopman(nn.Module):\n",
    "    def __init__(self, x_dim: int, z_dim: int, enc_hidden: tuple[int, ...], dec_hidden: tuple[int, ...]) -> None:\n",
    "        super().__init__()\n",
    "        self.enc = build_mlp(x_dim, enc_hidden, z_dim)\n",
    "        self.dec = build_mlp(z_dim, dec_hidden, x_dim)\n",
    "        self.K = nn.Parameter(torch.eye(z_dim))  # linear Koopman operator\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.enc(x)\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.dec(z)\n",
    "\n",
    "    def step_latent(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return z @ self.K.T\n",
    "\n",
    "def spectral_radius(K: torch.Tensor) -> torch.Tensor:\n",
    "    eigvals = torch.linalg.eigvals(K)\n",
    "    return torch.max(torch.abs(eigvals)).real\n",
    "\n",
    "def sample_batch_indices(T: int, rollout_len: int, batch_size: int) -> list[int]:\n",
    "    max_start = T - (rollout_len + 1)\n",
    "    if max_start < 0:\n",
    "        raise ValueError(f\"Not enough snapshots: T={T}, rollout_len={rollout_len}\")\n",
    "    return np.random.randint(0, max_start + 1, size=batch_size).tolist()\n",
    "\n",
    "def make_batch(Xp_seq_torch: torch.Tensor, idx0: list[int], rollout_len: int) -> torch.Tensor:\n",
    "    seqs = [Xp_seq_torch[i : i + rollout_len + 1] for i in idx0]\n",
    "    return torch.stack(seqs, dim=0)  # (B, L+1, x_dim)\n",
    "\n",
    "model = DeepKoopman(x_dim=x_dim, z_dim=Z_DIM, enc_hidden=ENC_HIDDEN, dec_hidden=DEC_HIDDEN).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"Training DeepKoopman: x_dim={x_dim}, z_dim={Z_DIM}, T={T_total}, rollout_len={ROLLOUT_LEN}\")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for _ in range(BATCHES_PER_EPOCH):\n",
    "        idx0 = sample_batch_indices(T_total, ROLLOUT_LEN, batch_size=BATCH_SIZE)\n",
    "        Xb = make_batch(Xp_torch, idx0, ROLLOUT_LEN)  # (B, L+1, x_dim)\n",
    "\n",
    "        B, Lp1, _ = Xb.shape\n",
    "        L = Lp1 - 1\n",
    "\n",
    "        z_true = model.encode(Xb.reshape(B * (L + 1), x_dim)).reshape(B, L + 1, Z_DIM)\n",
    "\n",
    "        # Recon\n",
    "        X_recon = model.decode(z_true.reshape(B * (L + 1), Z_DIM)).reshape(B, L + 1, x_dim)\n",
    "        loss_recon = mse(X_recon, Xb)\n",
    "\n",
    "        # Latent rollout from z0\n",
    "        z_list = [z_true[:, 0, :]]\n",
    "        for _k in range(L):\n",
    "            z_list.append(model.step_latent(z_list[-1]))\n",
    "        z_pred = torch.stack(z_list, dim=1)  # (B, L+1, Z_DIM)\n",
    "\n",
    "        X_pred = model.decode(z_pred.reshape(B * (L + 1), Z_DIM)).reshape(B, L + 1, x_dim)\n",
    "\n",
    "        loss_pred = mse(X_pred[:, 1:, :], Xb[:, 1:, :])\n",
    "        loss_lat  = mse(z_pred[:, 1:, :], z_true[:, 1:, :])\n",
    "\n",
    "        rho = spectral_radius(model.K)\n",
    "        loss_stab = torch.relu(rho - 1.0) ** 2\n",
    "\n",
    "        loss = W_RECON * loss_recon + W_PRED * loss_pred + W_LAT * loss_lat + W_STAB * loss_stab\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    if rank == 0 and (epoch == 1 or epoch % 100 == 0):\n",
    "        avg = float(np.mean(losses)) if losses else float(\"nan\")\n",
    "        with torch.no_grad():\n",
    "            rho_val = float(spectral_radius(model.K).cpu().item())\n",
    "        print(f\"Epoch {epoch:5d}/{EPOCHS} | loss={avg:.6e} | rho(K)={rho_val:.6f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# One-step forecast at next timestep\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "t_next = times[-1] + 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_last = Xp_torch[-1, :].unsqueeze(0)  # (1, x_dim)\n",
    "    z_last = model.encode(x_last)          # (1, z_dim)\n",
    "    z_next = model.step_latent(z_last)     # (1, z_dim)\n",
    "    x_next_p = model.decode(z_next).cpu().numpy()[0]  # (x_dim,)\n",
    "\n",
    "# Undo PCA + normalization\n",
    "if USE_PCA:\n",
    "    x_next_norm = pca.inverse_transform(x_next_p.reshape(1, -1))[0]\n",
    "else:\n",
    "    x_next_norm = x_next_p\n",
    "\n",
    "x_next_pred = (x_next_norm * X_std.reshape(-1) + X_mean.reshape(-1)).astype(np.float64)  # (n_points,)\n",
    "\n",
    "# Save prediction\n",
    "suffix = _case_suffix(PHI, LAT_SIZE)\n",
    "out_dir = BASE_DIR / f\"phi{PHI:.2f}\" / suffix\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out = pd.DataFrame(coords_ref, columns=SORT_COLS)\n",
    "out[f\"{VAR_NAME}_pred\"] = x_next_pred\n",
    "out_path = out_dir / f\"deepkoopman_pred_{VAR_NAME}_{t_next}_xgt{int(X_THESHOLD)}.csv\"\n",
    "out.to_csv(out_path, index=False)\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"Wrote:\", out_path)\n"
   ],
   "id": "8f3947e41b31f167",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 4GB Laptop GPU\n",
      "PCA: n_components=24, explained_var_sum=0.9407\n",
      "Training DeepKoopman: x_dim=24, z_dim=16, T=101, rollout_len=10\n",
      "Epoch     1/3000 | loss=1.405581e+04 | rho(K)=1.133281\n",
      "Epoch   100/3000 | loss=4.243264e+02 | rho(K)=1.091027\n",
      "Epoch   200/3000 | loss=4.082211e+01 | rho(K)=1.055555\n",
      "Epoch   300/3000 | loss=9.759146e+00 | rho(K)=1.045329\n",
      "Epoch   400/3000 | loss=1.507081e+00 | rho(K)=1.034297\n",
      "Epoch   500/3000 | loss=9.628716e-01 | rho(K)=1.030237\n",
      "Epoch   600/3000 | loss=1.960929e+00 | rho(K)=1.031726\n",
      "Epoch   700/3000 | loss=4.517496e-01 | rho(K)=1.027587\n",
      "Epoch   800/3000 | loss=6.893076e-01 | rho(K)=1.026291\n",
      "Epoch   900/3000 | loss=3.002577e-01 | rho(K)=1.025802\n",
      "Epoch  1000/3000 | loss=3.380327e-01 | rho(K)=1.027940\n",
      "Epoch  1100/3000 | loss=2.411925e-01 | rho(K)=1.026197\n",
      "Epoch  1200/3000 | loss=2.979660e-01 | rho(K)=1.026547\n",
      "Epoch  1300/3000 | loss=2.179507e-01 | rho(K)=1.024914\n",
      "Epoch  1400/3000 | loss=7.548174e-01 | rho(K)=1.022635\n",
      "Epoch  1500/3000 | loss=5.641560e-01 | rho(K)=1.022152\n",
      "Epoch  1600/3000 | loss=2.592971e-01 | rho(K)=1.022325\n",
      "Epoch  1700/3000 | loss=3.411081e-01 | rho(K)=1.025220\n",
      "Epoch  1800/3000 | loss=1.115051e+00 | rho(K)=1.025096\n",
      "Epoch  1900/3000 | loss=2.371698e-01 | rho(K)=1.022117\n",
      "Epoch  2000/3000 | loss=2.563293e-01 | rho(K)=1.020082\n",
      "Epoch  2100/3000 | loss=2.320597e-01 | rho(K)=1.019811\n",
      "Epoch  2200/3000 | loss=2.245278e-01 | rho(K)=1.018030\n",
      "Epoch  2300/3000 | loss=1.802494e-01 | rho(K)=1.017932\n",
      "Epoch  2400/3000 | loss=5.624605e-01 | rho(K)=1.021081\n",
      "Epoch  2500/3000 | loss=1.533419e-01 | rho(K)=1.017971\n",
      "Epoch  2600/3000 | loss=3.350485e-01 | rho(K)=1.022837\n",
      "Epoch  2700/3000 | loss=1.198122e-01 | rho(K)=1.017506\n",
      "Epoch  2800/3000 | loss=2.954996e+00 | rho(K)=1.021407\n",
      "Epoch  2900/3000 | loss=1.210528e-01 | rho(K)=1.017869\n",
      "Epoch  3000/3000 | loss=2.460916e-01 | rho(K)=1.020680\n",
      "Wrote: ..\\isocontours\\phi0.40\\h400x025_ref\\deepkoopman_pred_T_301_xgt300.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T17:29:59.967676Z",
     "start_time": "2025-12-24T17:29:42.787455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# BOX 3/3 — Plotting + comparison + error maps + saving (NO TITLES)\n",
    "#   Saves:\n",
    "#     prediction.png, true.png, predvstruth.png, error.png\n",
    "# ============================================================\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "# ---------- where to save figures ----------\n",
    "FIG_DIR = Path(r\"C:\\Users\\alexp\\Documents\\Bachelor Thesis\\report_figures\\results\\Koopman\")\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- build triangulation from coords_ref ----------\n",
    "x_xy = coords_ref[:, 0].astype(float)\n",
    "y_xy = coords_ref[:, 1].astype(float)\n",
    "triang = mtri.Triangulation(x_xy, y_xy)\n",
    "try:\n",
    "    analyzer = mtri.TriAnalyzer(triang)\n",
    "    triang.set_mask(analyzer.get_flat_tri_mask(min_circle_ratio=0.02))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "def save_tricontour_field(vals, fname, cbar_label, vmin=None, vmax=None, dpi=250):\n",
    "    fig = plt.figure(figsize=(7.2, 5.8))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    cf = ax.tricontourf(triang, vals, levels=60, vmin=vmin, vmax=vmax)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    # no title\n",
    "\n",
    "    cbar = fig.colorbar(cf, ax=ax, orientation=\"horizontal\", pad=0.08, fraction=0.06)\n",
    "    cbar.set_label(cbar_label)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    outpath = FIG_DIR / fname\n",
    "    fig.savefig(outpath, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", outpath)\n",
    "\n",
    "def save_scatter_true_vs_pred(true_vals, pred_vals, fname=\"predvstruth.png\", dpi=250):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.scatter(true_vals, pred_vals, s=2)\n",
    "    lo = float(min(true_vals.min(), pred_vals.min()))\n",
    "    hi = float(max(true_vals.max(), pred_vals.max()))\n",
    "    ax.plot([lo, hi], [lo, hi], linestyle=\"--\")\n",
    "\n",
    "    ax.set_xlabel(f\"{VAR_NAME}_true\")\n",
    "    ax.set_ylabel(f\"{VAR_NAME}_pred\")\n",
    "    # no title\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    outpath = FIG_DIR / fname\n",
    "    fig.savefig(outpath, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", outpath)\n",
    "\n",
    "# ---------- always save prediction ----------\n",
    "vmin_pred = float(np.percentile(x_next_pred, 0.5))\n",
    "vmax_pred = float(np.percentile(x_next_pred, 99.5))\n",
    "save_tricontour_field(\n",
    "    x_next_pred,\n",
    "    fname=\"prediction.png\",\n",
    "    cbar_label=f\"{VAR_NAME} (pred)\",\n",
    "    vmin=vmin_pred,\n",
    "    vmax=vmax_pred,\n",
    ")\n",
    "\n",
    "# ---------- load TRUE (if exists), then save true + scatter + abs error ----------\n",
    "path_true = field_csv_path(BASE_DIR, PHI, LAT_SIZE, t_next, POST)\n",
    "\n",
    "if path_true.exists():\n",
    "    coords_true_full, snap_true_full = read_field_sorted(path_true, VAR_NAME, SORT_COLS)\n",
    "\n",
    "    # Full coordinate check first\n",
    "    if coords_true_full.shape[0] != coords_ref_full.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"True next-step has different full point count: {coords_true_full.shape[0]} vs {coords_ref_full.shape[0]}\"\n",
    "        )\n",
    "\n",
    "    if COORD_TOL == 0.0:\n",
    "        same = np.array_equal(coords_true_full, coords_ref_full)\n",
    "    else:\n",
    "        same = np.allclose(coords_true_full, coords_ref_full, atol=COORD_TOL, rtol=0.0)\n",
    "\n",
    "    if not same:\n",
    "        raise ValueError(\"True next-step coordinates do not match reference coordinates.\")\n",
    "\n",
    "    snap_true = snap_true_full[mask_x].astype(np.float64)\n",
    "\n",
    "    # metrics\n",
    "    err = x_next_pred - snap_true\n",
    "    abs_err = np.abs(err)\n",
    "    rmse = float(np.sqrt(np.mean(err**2)))\n",
    "    rel_l2 = float(np.linalg.norm(err) / (np.linalg.norm(snap_true) + 1e-12))\n",
    "    print(f\"Next-step compare at t={t_next}: RMSE={rmse:.6e}, relL2={rel_l2:.6e}\")\n",
    "\n",
    "    # save error CSV (optional)\n",
    "    out_err = pd.DataFrame(coords_ref, columns=SORT_COLS)\n",
    "    out_err[f\"{VAR_NAME}_true\"] = snap_true\n",
    "    out_err[f\"{VAR_NAME}_pred\"] = x_next_pred\n",
    "    out_err[\"err\"] = err\n",
    "    out_err[\"abs_err\"] = abs_err\n",
    "    err_path = out_dir / f\"deepkoopman_err_{VAR_NAME}_{t_next}_xgt{int(X_THESHOLD)}.csv\"\n",
    "    out_err.to_csv(err_path, index=False)\n",
    "    print(\"Wrote:\", err_path)\n",
    "\n",
    "    # shared color scale for true/pred visuals\n",
    "    vmin_shared = float(min(np.percentile(snap_true, 0.5), np.percentile(x_next_pred, 0.5)))\n",
    "    vmax_shared = float(max(np.percentile(snap_true, 99.5), np.percentile(x_next_pred, 99.5)))\n",
    "\n",
    "    save_tricontour_field(\n",
    "        snap_true,\n",
    "        fname=\"true.png\",\n",
    "        cbar_label=f\"{VAR_NAME} (true)\",\n",
    "        vmin=vmin_shared,\n",
    "        vmax=vmax_shared,\n",
    "    )\n",
    "\n",
    "    save_scatter_true_vs_pred(\n",
    "        true_vals=snap_true,\n",
    "        pred_vals=x_next_pred,\n",
    "        fname=\"predvstruth.png\",\n",
    "    )\n",
    "\n",
    "    vmax_abs = float(np.percentile(abs_err, 99.0)) + 1e-30\n",
    "    save_tricontour_field(\n",
    "        abs_err,\n",
    "        fname=\"error.png\",\n",
    "        cbar_label=\"Absolute error\",\n",
    "        vmin=0.0,\n",
    "        vmax=vmax_abs,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"True next-step file does not exist; only prediction.png was saved.\")\n"
   ],
   "id": "b801ba0fd65ae017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\alexp\\Documents\\Bachelor Thesis\\report_figures\\results\\Koopman\\prediction.png\n",
      "Next-step compare at t=301: RMSE=4.825157e-01, relL2=1.170921e-01\n",
      "Wrote: ..\\isocontours\\phi0.40\\h400x025_ref\\deepkoopman_err_T_301_xgt300.csv\n",
      "Saved: C:\\Users\\alexp\\Documents\\Bachelor Thesis\\report_figures\\results\\Koopman\\true.png\n",
      "Saved: C:\\Users\\alexp\\Documents\\Bachelor Thesis\\report_figures\\results\\Koopman\\predvstruth.png\n",
      "Saved: C:\\Users\\alexp\\Documents\\Bachelor Thesis\\report_figures\\results\\Koopman\\error.png\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "30aa16d7819ff789"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
