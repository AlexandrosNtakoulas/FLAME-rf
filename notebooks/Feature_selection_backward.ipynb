{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1f7d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving outputs to: /media/alexandros/OS/Documents and Settings/alexp/Documents/Bachelor Thesis/report_figures/results/backward_selection/lat_100/t_200/h_100_t_200_iso_0.8\n",
      "Pooled rows total: n=3845 across timesteps=[200]\n",
      "\n",
      "Cluster features (common across all timesteps): ['curvature']\n",
      "Model features (common across all timesteps):   ['curvature', 'dTdx', 'dTdy', 'dcurvdx', 'dcurvdy', 'du_ndx', 'du_ndy', 'du_tdx', 'du_tdy', 'normal_strain_rate', 'tangential_strain_rate', 'u_n', 'u_t', 'vorticity']\n",
      "\n",
      "After dropna on required (cluster+model+target): n=3845\n",
      "\n",
      "Global backward selection:\n",
      "['dTdx', 'dTdy', 'du_ndx', 'du_tdy']\n",
      "\n",
      "Global model accuracy: R2=0.9182 | RMSE=1.039460e-01\n",
      "\n",
      "[INFO] Wrote global selection: /media/alexandros/OS/Documents and Settings/alexp/Documents/Bachelor Thesis/report_figures/results/backward_selection/lat_100/t_200/h_100_t_200_iso_0.8/backward_selected_global.csv\n",
      "\n",
      "Curvature bins: (-0.1, 0.1) -> clusters 0..2\n",
      "\n",
      "--- Cluster 0 (CURVATURE BIN) | n=773 ---\n",
      "Accuracy: R2=0.9391 | RMSE=1.586206e-01\n",
      "Selected features (backward order):\n",
      "  01. curvature\n",
      "  02. dTdx\n",
      "  03. dTdy\n",
      "  04. dcurvdx\n",
      "\n",
      "--- Cluster 1 (CURVATURE BIN) | n=2060 ---\n",
      "Accuracy: R2=0.9893 | RMSE=1.943072e-02\n",
      "Selected features (backward order):\n",
      "  01. dTdy\n",
      "  02. dcurvdy\n",
      "  03. u_n\n",
      "  04. u_t\n",
      "\n",
      "--- Cluster 2 (CURVATURE BIN) | n=1012 ---\n",
      "Accuracy: R2=0.9890 | RMSE=3.426117e-02\n",
      "Selected features (backward order):\n",
      "  01. dTdx\n",
      "  02. dTdy\n",
      "  03. du_ndx\n",
      "  04. u_t\n",
      "\n",
      "Summary (backward selected features per cluster):\n",
      " cluster  rank   feature  n_cluster\n",
      "       0     1 curvature        773\n",
      "       0     2      dTdx        773\n",
      "       0     3      dTdy        773\n",
      "       0     4   dcurvdx        773\n",
      "       1     1      dTdy       2060\n",
      "       1     2   dcurvdy       2060\n",
      "       1     3       u_n       2060\n",
      "       1     4       u_t       2060\n",
      "       2     1      dTdx       1012\n",
      "       2     2      dTdy       1012\n",
      "       2     3    du_ndx       1012\n",
      "       2     4       u_t       1012\n",
      "\n",
      "[INFO] Wrote per-cluster selection: /media/alexandros/OS/Documents and Settings/alexp/Documents/Bachelor Thesis/report_figures/results/backward_selection/lat_100/t_200/h_100_t_200_iso_0.8/backward_selected_per_cluster.csv\n",
      "\n",
      "Per-cluster model accuracy:\n",
      " cluster  n_cluster  n_features       r2     rmse\n",
      "       0        773           4 0.939112 0.158621\n",
      "       1       2060           4 0.989328 0.019431\n",
      "       2       1012           4 0.989015 0.034261\n",
      "\n",
      "[INFO] Wrote per-cluster metrics: /media/alexandros/OS/Documents and Settings/alexp/Documents/Bachelor Thesis/report_figures/results/backward_selection/lat_100/t_200/h_100_t_200_iso_0.8/backward_cluster_metrics.csv\n",
      "\n",
      "Saved outputs to: /media/alexandros/OS/Documents and Settings/alexp/Documents/Bachelor Thesis/report_figures/results/backward_selection/lat_100/t_200/h_100_t_200_iso_0.8\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")   # go from notebooks/ to project root\n",
    "\n",
    "from flamekit.io_fronts import Case, load_fronts\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# =========================\n",
    "# USER SETTINGS\n",
    "# =========================\n",
    "\n",
    "BASE_DIR = Path(r\"/media/alexandros/OS/Documents and Settings/alexp/Documents/Bachelor Thesis/Code/isocontours\")\n",
    "PHI = 0.40\n",
    "LAT_SIZE = \"100\"\n",
    "POST = True\n",
    "\n",
    "TIME_STEPS = [200]\n",
    "ISOLEVEL = 0.8\n",
    "TARGET_VAR = \"DW_FDS\"\n",
    "\n",
    "CLUSTER_ON_SPATIAL = False\n",
    "\n",
    "CLUSTER_FEATURES_INCLUDE = {\n",
    "    \"curvature\",\n",
    "}\n",
    "\n",
    "MODEL_FEATURES_INCLUDE = {\n",
    "    \"curvature\",\n",
    "    \"dcurvdx\",\n",
    "    \"dcurvdy\",\n",
    "    \"tangential_strain_rate\",\n",
    "    \"normal_strain_rate\",\n",
    "    \"vorticity\",\n",
    "    \"u_n\",\n",
    "    \"u_t\",\n",
    "    \"du_ndx\",\n",
    "    \"du_ndy\",\n",
    "    \"du_tdx\",\n",
    "    \"du_tdy\",\n",
    "    \"dTdx\",\n",
    "    \"dTdy\",\n",
    "}\n",
    "\n",
    "FEATURES_EXCLUDE = set()\n",
    "\n",
    "CURVATURE_COLUMN = \"curvature\"\n",
    "CURVATURE_BOUNDS = (-0.1, 0.1)  # low/high thresholds for 3 bins\n",
    "N_CLUSTERS = len(CURVATURE_BOUNDS) + 1\n",
    "\n",
    "MIN_CLUSTER_SAMPLES = 50\n",
    "RANDOM_STATE = 0\n",
    "TEST_SIZE = 0.25\n",
    "\n",
    "# Backward selection\n",
    "BACKWARD_N_FEATURES_GLOBAL = 4\n",
    "BACKWARD_N_FEATURES_CLUSTER = 4\n",
    "SFS_SCORING = \"r2\"\n",
    "SFS_CV_SPLITS = 3\n",
    "\n",
    "MODEL_PARAMS = dict(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PLOT SAVING (folder naming convention)\n",
    "# =========================\n",
    "\n",
    "OUTPUT_BASE_DIR = Path(r\"/media/alexandros/OS/Documents and Settings/alexp/Documents/Bachelor Thesis/report_figures/results/backward_selection\")\n",
    "\n",
    "def _time_steps_tag(time_steps: list[int]) -> str:\n",
    "    if not time_steps:\n",
    "        return \"t_none\"\n",
    "    if len(time_steps) == 1:\n",
    "        return f\"t_{time_steps[0]}\"\n",
    "    t_min = min(time_steps)\n",
    "    t_max = max(time_steps)\n",
    "    return f\"t_{t_min}_to_{t_max}\"\n",
    "\n",
    "RUN_DIR = OUTPUT_BASE_DIR / f\"lat_{LAT_SIZE}\" / _time_steps_tag(TIME_STEPS)\n",
    "TS_TAG = \"_\".join(map(str, TIME_STEPS))\n",
    "SAVE_DIR = RUN_DIR / f\"h_{LAT_SIZE}_t_{TS_TAG}_iso_{ISOLEVEL}\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FIG_DPI = 300\n",
    "\n",
    "def _safe_name(s: str) -> str:\n",
    "    return \"\".join(ch if (ch.isalnum() or ch in \"._-\") else \"_\" for ch in s)\n",
    "\n",
    "def save_png(stem: str, dpi: int = FIG_DPI):\n",
    "    \"\"\"Save current matplotlib figure as PNG to SAVE_DIR.\"\"\"\n",
    "    fname = SAVE_DIR / f\"{_safe_name(stem)}.png\"\n",
    "    plt.gcf().savefig(fname, dpi=dpi, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "\n",
    "def save_then_show(stem: str, dpi: int = FIG_DPI):\n",
    "    save_png(stem, dpi=dpi)\n",
    "    plt.show()\n",
    "\n",
    "print(f\"[INFO] Saving outputs to: {SAVE_DIR}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "\n",
    "def _numeric_cols(df: pd.DataFrame) -> List[str]:\n",
    "    return [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "def resolve_features(\n",
    "    df: pd.DataFrame,\n",
    "    include: Optional[List[str] | set[str]],\n",
    "    exclude: set[str],\n",
    ") -> List[str]:\n",
    "    num = set(_numeric_cols(df))\n",
    "    feats = num if include is None else set(include).intersection(num)\n",
    "    feats = feats.difference(exclude)\n",
    "    return sorted(feats)\n",
    "\n",
    "def intersect_feature_space(feature_sets: List[set[str]]) -> List[str]:\n",
    "    if not feature_sets:\n",
    "        return []\n",
    "    common = set.intersection(*feature_sets)\n",
    "    return sorted(common)\n",
    "\n",
    "def run_backward_selection(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    feature_names: List[str],\n",
    "    n_features_to_select: int,\n",
    "    random_state: int,\n",
    "    scoring: str,\n",
    "    cv_splits: int,\n",
    ") -> List[str]:\n",
    "    if X.shape[1] == 0:\n",
    "        return []\n",
    "\n",
    "    n_features_to_select = int(min(n_features_to_select, X.shape[1]))\n",
    "    cv = KFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    model = RandomForestRegressor(**MODEL_PARAMS)\n",
    "    sfs = SequentialFeatureSelector(\n",
    "        estimator=model,\n",
    "        n_features_to_select=n_features_to_select,\n",
    "        direction=\"backward\",\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    sfs.fit(X, y)\n",
    "    mask = sfs.get_support()\n",
    "    return [f for f, keep in zip(feature_names, mask) if keep]\n",
    "\n",
    "\n",
    "def evaluate_selected_model(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    test_size: float,\n",
    "    random_state: int,\n",
    ") -> Tuple[float, float]:\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    model = RandomForestRegressor(**MODEL_PARAMS)\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    ypred = model.predict(Xte)\n",
    "    r2 = float(r2_score(yte, ypred))\n",
    "    rmse = float(np.sqrt(mean_squared_error(yte, ypred)))\n",
    "    return r2, rmse\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LOAD + POOL\n",
    "# ============================================================\n",
    "\n",
    "dfs = []\n",
    "cluster_feature_sets_per_t: List[set[str]] = []\n",
    "model_feature_sets_per_t: List[set[str]] = []\n",
    "\n",
    "cluster_include = set(CLUSTER_FEATURES_INCLUDE)\n",
    "if CLUSTER_ON_SPATIAL:\n",
    "    cluster_include = cluster_include.union({\"x\", \"y\", \"z\"})\n",
    "\n",
    "model_include = set(MODEL_FEATURES_INCLUDE)\n",
    "\n",
    "for ts in TIME_STEPS:\n",
    "    CASE = Case(\n",
    "        base_dir=BASE_DIR,\n",
    "        phi=PHI,\n",
    "        lat_size=LAT_SIZE,\n",
    "        time_step=ts,\n",
    "        post=POST,\n",
    "    )\n",
    "\n",
    "    fronts = load_fronts(CASE, [ISOLEVEL])\n",
    "    if ISOLEVEL not in fronts:\n",
    "        raise ValueError(f\"ISOLEVEL {ISOLEVEL} not found for timestep {ts}\")\n",
    "\n",
    "    df_t = fronts[ISOLEVEL].copy()\n",
    "    df_t[\"c_iso\"] = float(ISOLEVEL)\n",
    "    df_t[\"timestep\"] = int(ts)\n",
    "\n",
    "    if TARGET_VAR not in df_t.columns:\n",
    "        raise ValueError(f\"TARGET_VAR '{TARGET_VAR}' not found for timestep {ts}\")\n",
    "\n",
    "    cl_feats_t = set(resolve_features(df_t, cluster_include, FEATURES_EXCLUDE))\n",
    "    ml_feats_t = set(resolve_features(df_t, model_include, FEATURES_EXCLUDE))\n",
    "\n",
    "    cluster_feature_sets_per_t.append(cl_feats_t)\n",
    "    model_feature_sets_per_t.append(ml_feats_t)\n",
    "\n",
    "    dfs.append(df_t)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Pooled rows total: n={len(df_all)} across timesteps={TIME_STEPS}\")\n",
    "\n",
    "cluster_features = intersect_feature_space(cluster_feature_sets_per_t)\n",
    "model_features = intersect_feature_space(model_feature_sets_per_t)\n",
    "\n",
    "if len(cluster_features) == 0:\n",
    "    raise ValueError(\"No common numeric CLUSTER features across requested timesteps. Adjust CLUSTER_FEATURES_INCLUDE.\")\n",
    "if len(model_features) == 0:\n",
    "    raise ValueError(\"No common numeric MODEL features across requested timesteps. Adjust MODEL_FEATURES_INCLUDE.\")\n",
    "\n",
    "print(f\"\\nCluster features (common across all timesteps): {cluster_features}\")\n",
    "print(f\"Model features (common across all timesteps):   {model_features}\")\n",
    "\n",
    "required = sorted(set(cluster_features).union(model_features).union({TARGET_VAR, CURVATURE_COLUMN}))\n",
    "dfc = df_all.dropna(subset=required).copy()\n",
    "print(f\"\\nAfter dropna on required (cluster+model+target): n={len(dfc)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GLOBAL BACKWARD SELECTION\n",
    "# ============================================================\n",
    "\n",
    "X_all = dfc[model_features].to_numpy()\n",
    "y_all = dfc[TARGET_VAR].to_numpy()\n",
    "\n",
    "selected_global = run_backward_selection(\n",
    "    X=X_all,\n",
    "    y=y_all,\n",
    "    feature_names=model_features,\n",
    "    n_features_to_select=BACKWARD_N_FEATURES_GLOBAL,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scoring=SFS_SCORING,\n",
    "    cv_splits=SFS_CV_SPLITS,\n",
    ")\n",
    "\n",
    "print(\"\\nGlobal backward selection:\")\n",
    "print(selected_global)\n",
    "\n",
    "r2_global = np.nan\n",
    "rmse_global = np.nan\n",
    "if selected_global:\n",
    "    X_sel = dfc[selected_global].to_numpy()\n",
    "    r2_global, rmse_global = evaluate_selected_model(\n",
    "        X=X_sel,\n",
    "        y=y_all,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "summary_global = pd.DataFrame({\n",
    "    \"rank\": list(range(1, len(selected_global) + 1)),\n",
    "    \"feature\": selected_global,\n",
    "})\n",
    "summary_global[\"r2\"] = r2_global\n",
    "summary_global[\"rmse\"] = rmse_global\n",
    "summary_global_csv = SAVE_DIR / \"backward_selected_global.csv\"\n",
    "summary_global.to_csv(summary_global_csv, index=False)\n",
    "print(f\"\\nGlobal model accuracy: R2={r2_global:.4f} | RMSE={rmse_global:.6e}\")\n",
    "print(f\"\\n[INFO] Wrote global selection: {summary_global_csv}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CURVATURE BINNING (predefined thresholds)\n",
    "# ============================================================\n",
    "\n",
    "curv_col = CURVATURE_COLUMN\n",
    "if curv_col not in dfc.columns:\n",
    "    raise ValueError(f\"CURVATURE_COLUMN '{curv_col}' not found in dataframe\")\n",
    "\n",
    "if len(CURVATURE_BOUNDS) != 2:\n",
    "    raise ValueError(\"CURVATURE_BOUNDS must contain exactly two values\")\n",
    "low, high = CURVATURE_BOUNDS\n",
    "if low >= high:\n",
    "    raise ValueError(\"CURVATURE_BOUNDS must be strictly increasing (low < high)\")\n",
    "\n",
    "dfc[\"cluster\"] = np.digitize(\n",
    "    dfc[curv_col].to_numpy(),\n",
    "    bins=[low, high],\n",
    "    right=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nCurvature bins: {CURVATURE_BOUNDS} -> clusters 0..{N_CLUSTERS - 1}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Per-cluster backward selection\n",
    "# ============================================================\n",
    "\n",
    "selected_rows: List[dict] = []\n",
    "cluster_metrics_rows: List[dict] = []\n",
    "\n",
    "for cl in range(N_CLUSTERS):\n",
    "    sub = dfc[dfc[\"cluster\"] == cl].copy()\n",
    "    n_cl = len(sub)\n",
    "    print(f\"\\n--- Cluster {cl} (CURVATURE BIN) | n={n_cl} ---\")\n",
    "\n",
    "    if n_cl < MIN_CLUSTER_SAMPLES:\n",
    "        print(f\"Skipping (n < MIN_CLUSTER_SAMPLES={MIN_CLUSTER_SAMPLES})\")\n",
    "        continue\n",
    "\n",
    "    X = sub[model_features].to_numpy()\n",
    "    y = sub[TARGET_VAR].to_numpy()\n",
    "\n",
    "    selected = run_backward_selection(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        feature_names=model_features,\n",
    "        n_features_to_select=BACKWARD_N_FEATURES_CLUSTER,\n",
    "        random_state=RANDOM_STATE,\n",
    "        scoring=SFS_SCORING,\n",
    "        cv_splits=SFS_CV_SPLITS,\n",
    "    )\n",
    "\n",
    "    r2_cl = np.nan\n",
    "    rmse_cl = np.nan\n",
    "    if selected:\n",
    "        X_sel = sub[selected].to_numpy()\n",
    "        r2_cl, rmse_cl = evaluate_selected_model(\n",
    "            X=X_sel,\n",
    "            y=y,\n",
    "            test_size=TEST_SIZE,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "\n",
    "    cluster_metrics_rows.append({\n",
    "        \"cluster\": cl,\n",
    "        \"n_cluster\": int(n_cl),\n",
    "        \"n_features\": int(len(selected)),\n",
    "        \"r2\": r2_cl,\n",
    "        \"rmse\": rmse_cl,\n",
    "    })\n",
    "\n",
    "    print(f\"Accuracy: R2={r2_cl:.4f} | RMSE={rmse_cl:.6e}\")\n",
    "    print(\"Selected features (backward order):\")\n",
    "    for i, f in enumerate(selected, 1):\n",
    "        print(f\"  {i:02d}. {f}\")\n",
    "        selected_rows.append({\n",
    "            \"cluster\": cl,\n",
    "            \"rank\": i,\n",
    "            \"feature\": f,\n",
    "            \"n_cluster\": int(n_cl),\n",
    "        })\n",
    "\n",
    "if selected_rows:\n",
    "    summary_df = pd.DataFrame(selected_rows)\n",
    "    summary_csv = SAVE_DIR / \"backward_selected_per_cluster.csv\"\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "\n",
    "    print(\"\\nSummary (backward selected features per cluster):\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    print(f\"\\n[INFO] Wrote per-cluster selection: {summary_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo clusters met MIN_CLUSTER_SAMPLES; no per-cluster results to report.\")\n",
    "\n",
    "if cluster_metrics_rows:\n",
    "    metrics_df = pd.DataFrame(cluster_metrics_rows)\n",
    "    metrics_csv = SAVE_DIR / \"backward_cluster_metrics.csv\"\n",
    "    metrics_df.to_csv(metrics_csv, index=False)\n",
    "    print(\"\\nPer-cluster model accuracy:\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "    print(f\"\\n[INFO] Wrote per-cluster metrics: {metrics_csv}\")\n",
    "\n",
    "print(f\"\\nSaved outputs to: {SAVE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38ebcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myproject)",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
