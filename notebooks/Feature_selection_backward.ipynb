{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e9e957",
   "metadata": {},
   "source": [
    "## Descriptions:\n",
    "Reads isocontours from a number of timesteps and seperates the data according to the algebraic value of curvature into groups. For example using 3 groups we can have Group 0 with curvature below -0.01, Group 1 with -0.01< curvature < 0.01 and Group 2 with curvature > 0.01. Then it runs backward feature selection both globally(All of the groups together) as well as for each group individually and outputs the N best features, where the number N is user defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f189f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from flamekit.io_fronts import Case, load_fronts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a557ff",
   "metadata": {},
   "source": [
    "### Read config file and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1f7d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving outputs to: /media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/report_figures/results/backward_selection/lat_100/t_200/h_100_t_200_iso_0.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "CONFIG_PATH = PROJECT_ROOT / \"notebooks\" / \"configs\" / \"Feature_selection_backward.yaml\"\n",
    "CFG = yaml.safe_load(CONFIG_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "BASE_DIR = PROJECT_ROOT / Path(CFG[\"BASE_DIR\"])\n",
    "PHI = float(CFG[\"PHI\"])\n",
    "LAT_SIZE = str(CFG[\"LAT_SIZE\"])\n",
    "POST = bool(CFG[\"POST\"])\n",
    "\n",
    "TIME_STEPS = list(CFG[\"TIME_STEPS\"])\n",
    "ISOLEVEL = float(CFG[\"ISOLEVEL\"])\n",
    "TARGET_VAR = str(CFG[\"TARGET_VAR\"])\n",
    "\n",
    "CLUSTER_ON_SPATIAL = bool(CFG[\"CLUSTER_ON_SPATIAL\"])\n",
    "\n",
    "CLUSTER_FEATURES_INCLUDE = set(CFG[\"CLUSTER_FEATURES_INCLUDE\"])\n",
    "\n",
    "MODEL_FEATURES_INCLUDE = set(CFG[\"MODEL_FEATURES_INCLUDE\"])\n",
    "\n",
    "FEATURES_EXCLUDE = set(CFG.get(\"FEATURES_EXCLUDE\", []))\n",
    "\n",
    "CURVATURE_COLUMN = str(CFG[\"CURVATURE_COLUMN\"])\n",
    "CURVATURE_BOUNDS = tuple(CFG[\"CURVATURE_BOUNDS\"])\n",
    "N_CLUSTERS = len(CURVATURE_BOUNDS) + 1\n",
    "\n",
    "MIN_CLUSTER_SAMPLES = int(CFG[\"MIN_CLUSTER_SAMPLES\"])\n",
    "RANDOM_STATE = int(CFG[\"RANDOM_STATE\"])\n",
    "TEST_SIZE = float(CFG[\"TEST_SIZE\"])\n",
    "\n",
    "# Backward selection\n",
    "BACKWARD_N_FEATURES_GLOBAL = int(CFG[\"BACKWARD_N_FEATURES_GLOBAL\"])\n",
    "BACKWARD_N_FEATURES_CLUSTER = int(CFG[\"BACKWARD_N_FEATURES_CLUSTER\"])\n",
    "SFS_SCORING = str(CFG[\"SFS_SCORING\"])\n",
    "SFS_CV_SPLITS = int(CFG[\"SFS_CV_SPLITS\"])\n",
    "\n",
    "MODEL_PARAMS = dict(CFG[\"MODEL_PARAMS\"])\n",
    "MODEL_PARAMS.setdefault(\"random_state\", RANDOM_STATE)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PLOT SAVING (folder naming convention)\n",
    "# =========================\n",
    "\n",
    "OUTPUT_BASE_DIR = PROJECT_ROOT / Path(CFG[\"OUTPUT_BASE_DIR\"])\n",
    "\n",
    "def _time_steps_tag(time_steps: list[int]) -> str:\n",
    "    if not time_steps:\n",
    "        return \"t_none\"\n",
    "    if len(time_steps) == 1:\n",
    "        return f\"t_{time_steps[0]}\"\n",
    "    t_min = min(time_steps)\n",
    "    t_max = max(time_steps)\n",
    "    return f\"t_{t_min}_to_{t_max}\"\n",
    "\n",
    "RUN_DIR = OUTPUT_BASE_DIR / f\"lat_{LAT_SIZE}\" / _time_steps_tag(TIME_STEPS)\n",
    "TS_TAG = \"_\".join(map(str, TIME_STEPS))\n",
    "SAVE_DIR = RUN_DIR / f\"h_{LAT_SIZE}_t_{TS_TAG}_iso_{ISOLEVEL}\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FIG_DPI = int(CFG[\"FIG_DPI\"])\n",
    "\n",
    "def _safe_name(s: str) -> str:\n",
    "    return \"\".join(ch if (ch.isalnum() or ch in \"._-\") else \"_\" for ch in s)\n",
    "\n",
    "def save_png(stem: str, dpi: int = FIG_DPI):\n",
    "    \"\"\"Save current matplotlib figure as PNG to SAVE_DIR.\"\"\"\n",
    "    fname = SAVE_DIR / f\"{_safe_name(stem)}.png\"\n",
    "    plt.gcf().savefig(fname, dpi=dpi, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "\n",
    "def save_then_show(stem: str, dpi: int = FIG_DPI):\n",
    "    save_png(stem, dpi=dpi)\n",
    "    plt.show()\n",
    "\n",
    "print(f\"[INFO] Saving outputs to: {SAVE_DIR}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "\n",
    "def _numeric_cols(df: pd.DataFrame) -> List[str]:\n",
    "    return [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "def resolve_features(\n",
    "    df: pd.DataFrame,\n",
    "    include: Optional[List[str] | set[str]],\n",
    "    exclude: set[str],\n",
    ") -> List[str]:\n",
    "    num = set(_numeric_cols(df))\n",
    "    feats = num if include is None else set(include).intersection(num)\n",
    "    feats = feats.difference(exclude)\n",
    "    return sorted(feats)\n",
    "\n",
    "def intersect_feature_space(feature_sets: List[set[str]]) -> List[str]:\n",
    "    if not feature_sets:\n",
    "        return []\n",
    "    common = set.intersection(*feature_sets)\n",
    "    return sorted(common)\n",
    "\n",
    "def run_backward_selection(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    feature_names: List[str],\n",
    "    n_features_to_select: int,\n",
    "    random_state: int,\n",
    "    scoring: str,\n",
    "    cv_splits: int,\n",
    ") -> List[str]:\n",
    "    if X.shape[1] == 0:\n",
    "        return []\n",
    "\n",
    "    n_features_to_select = int(min(n_features_to_select, X.shape[1]))\n",
    "    cv = KFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    model = RandomForestRegressor(**MODEL_PARAMS)\n",
    "    sfs = SequentialFeatureSelector(\n",
    "        estimator=model,\n",
    "        n_features_to_select=n_features_to_select,\n",
    "        direction=\"backward\",\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    sfs.fit(X, y)\n",
    "    mask = sfs.get_support()\n",
    "    return [f for f, keep in zip(feature_names, mask) if keep]\n",
    "\n",
    "\n",
    "def evaluate_selected_model(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    test_size: float,\n",
    "    random_state: int,\n",
    ") -> Tuple[float, float]:\n",
    "    Xtr, Xte, ytr, yte = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    model = RandomForestRegressor(**MODEL_PARAMS)\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    ypred = model.predict(Xte)\n",
    "    r2 = float(r2_score(yte, ypred))\n",
    "    rmse = float(np.sqrt(mean_squared_error(yte, ypred)))\n",
    "    return r2, rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983d273",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503b62ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/isocontours/phi0.40/extracted_flame_front_post_200_iso_0.8.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m TIME_STEPS:\n\u001b[32m     12\u001b[39m     CASE = Case(\n\u001b[32m     13\u001b[39m         base_dir=BASE_DIR,\n\u001b[32m     14\u001b[39m         phi=PHI,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m         post=POST,\n\u001b[32m     18\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     fronts = \u001b[43mload_fronts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCASE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mISOLEVEL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ISOLEVEL \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m fronts:\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mISOLEVEL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mISOLEVEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found for timestep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/flamekit/io_fronts.py:59\u001b[39m, in \u001b[36mload_fronts\u001b[39m\u001b[34m(c, isolevels, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_fronts\u001b[39m(\n\u001b[32m     55\u001b[39m     c: Case,\n\u001b[32m     56\u001b[39m     isolevels: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[32m     57\u001b[39m     **kwargs,\n\u001b[32m     58\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, pd.DataFrame]:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mfloat\u001b[39m(iso): \u001b[43mload_front_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miso\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m iso \u001b[38;5;129;01min\u001b[39;00m isolevels}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/flamekit/io_fronts.py:41\u001b[39m, in \u001b[36mload_front_csv\u001b[39m\u001b[34m(c, iso, dtype, required_cols)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_front_csv\u001b[39m(\n\u001b[32m     34\u001b[39m     c: Case,\n\u001b[32m     35\u001b[39m     iso: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m     required_cols: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     39\u001b[39m ) -> pd.DataFrame:\n\u001b[32m     40\u001b[39m     fp = front_path(c, iso)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     44\u001b[39m         num_cols = df.select_dtypes(include=[np.number]).columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/myproject/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/myproject/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/myproject/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/myproject/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/myproject/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/media/alexandros/OS/Users/alexp/Documents/Bachelor Thesis/Code/isocontours/phi0.40/extracted_flame_front_post_200_iso_0.8.csv'"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "cluster_feature_sets_per_t: List[set[str]] = []\n",
    "model_feature_sets_per_t: List[set[str]] = []\n",
    "\n",
    "cluster_include = set(CLUSTER_FEATURES_INCLUDE)\n",
    "if CLUSTER_ON_SPATIAL:\n",
    "    cluster_include = cluster_include.union({\"x\", \"y\", \"z\"})\n",
    "\n",
    "model_include = set(MODEL_FEATURES_INCLUDE)\n",
    "\n",
    "for ts in TIME_STEPS:\n",
    "    CASE = Case(\n",
    "        base_dir=BASE_DIR,\n",
    "        phi=PHI,\n",
    "        lat_size=LAT_SIZE,\n",
    "        time_step=ts,\n",
    "        post=POST,\n",
    "    )\n",
    "\n",
    "    fronts = load_fronts(CASE, [ISOLEVEL])\n",
    "    if ISOLEVEL not in fronts:\n",
    "        raise ValueError(f\"ISOLEVEL {ISOLEVEL} not found for timestep {ts}\")\n",
    "\n",
    "    df_t = fronts[ISOLEVEL].copy()\n",
    "    df_t[\"c_iso\"] = float(ISOLEVEL)\n",
    "    df_t[\"timestep\"] = int(ts)\n",
    "\n",
    "    if TARGET_VAR not in df_t.columns:\n",
    "        raise ValueError(f\"TARGET_VAR '{TARGET_VAR}' not found for timestep {ts}\")\n",
    "\n",
    "    cl_feats_t = set(resolve_features(df_t, cluster_include, FEATURES_EXCLUDE))\n",
    "    ml_feats_t = set(resolve_features(df_t, model_include, FEATURES_EXCLUDE))\n",
    "\n",
    "    cluster_feature_sets_per_t.append(cl_feats_t)\n",
    "    model_feature_sets_per_t.append(ml_feats_t)\n",
    "\n",
    "    dfs.append(df_t)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Pooled rows total: n={len(df_all)} across timesteps={TIME_STEPS}\")\n",
    "\n",
    "cluster_features = intersect_feature_space(cluster_feature_sets_per_t)\n",
    "model_features = intersect_feature_space(model_feature_sets_per_t)\n",
    "\n",
    "if len(cluster_features) == 0:\n",
    "    raise ValueError(\"No common numeric CLUSTER features across requested timesteps. Adjust CLUSTER_FEATURES_INCLUDE.\")\n",
    "if len(model_features) == 0:\n",
    "    raise ValueError(\"No common numeric MODEL features across requested timesteps. Adjust MODEL_FEATURES_INCLUDE.\")\n",
    "\n",
    "print(f\"\\nCluster features (common across all timesteps): {cluster_features}\")\n",
    "print(f\"Model features (common across all timesteps):   {model_features}\")\n",
    "\n",
    "required = sorted(set(cluster_features).union(model_features).union({TARGET_VAR, CURVATURE_COLUMN}))\n",
    "dfc = df_all.dropna(subset=required).copy()\n",
    "print(f\"\\nAfter dropna on required (cluster+model+target): n={len(dfc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ff478",
   "metadata": {},
   "source": [
    "### Global backward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = dfc[model_features].to_numpy()\n",
    "y_all = dfc[TARGET_VAR].to_numpy()\n",
    "\n",
    "selected_global = run_backward_selection(\n",
    "    X=X_all,\n",
    "    y=y_all,\n",
    "    feature_names=model_features,\n",
    "    n_features_to_select=BACKWARD_N_FEATURES_GLOBAL,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scoring=SFS_SCORING,\n",
    "    cv_splits=SFS_CV_SPLITS,\n",
    ")\n",
    "\n",
    "print(\"\\nGlobal backward selection:\")\n",
    "print(selected_global)\n",
    "\n",
    "r2_global = np.nan\n",
    "rmse_global = np.nan\n",
    "if selected_global:\n",
    "    X_sel = dfc[selected_global].to_numpy()\n",
    "    r2_global, rmse_global = evaluate_selected_model(\n",
    "        X=X_sel,\n",
    "        y=y_all,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "summary_global = pd.DataFrame({\n",
    "    \"rank\": list(range(1, len(selected_global) + 1)),\n",
    "    \"feature\": selected_global,\n",
    "})\n",
    "summary_global[\"r2\"] = r2_global\n",
    "summary_global[\"rmse\"] = rmse_global\n",
    "summary_global_csv = SAVE_DIR / \"backward_selected_global.csv\"\n",
    "summary_global.to_csv(summary_global_csv, index=False)\n",
    "print(f\"\\nGlobal model accuracy: R2={r2_global:.4f} | RMSE={rmse_global:.6e}\")\n",
    "print(f\"\\n[INFO] Wrote global selection: {summary_global_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a50dd",
   "metadata": {},
   "source": [
    "### Curvature binnning (predefined thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd47a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curv_col = CURVATURE_COLUMN\n",
    "if curv_col not in dfc.columns:\n",
    "    raise ValueError(f\"CURVATURE_COLUMN '{curv_col}' not found in dataframe\")\n",
    "\n",
    "if len(CURVATURE_BOUNDS) != 2:\n",
    "    raise ValueError(\"CURVATURE_BOUNDS must contain exactly two values\")\n",
    "low, high = CURVATURE_BOUNDS\n",
    "if low >= high:\n",
    "    raise ValueError(\"CURVATURE_BOUNDS must be strictly increasing (low < high)\")\n",
    "\n",
    "dfc[\"cluster\"] = np.digitize(\n",
    "    dfc[curv_col].to_numpy(),\n",
    "    bins=[low, high],\n",
    "    right=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nCurvature bins: {CURVATURE_BOUNDS} -> clusters 0..{N_CLUSTERS - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995d788",
   "metadata": {},
   "source": [
    "### Per-cluster backward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows: List[dict] = []\n",
    "cluster_metrics_rows: List[dict] = []\n",
    "\n",
    "for cl in range(N_CLUSTERS):\n",
    "    sub = dfc[dfc[\"cluster\"] == cl].copy()\n",
    "    n_cl = len(sub)\n",
    "    print(f\"\\n--- Cluster {cl} (CURVATURE BIN) | n={n_cl} ---\")\n",
    "\n",
    "    if n_cl < MIN_CLUSTER_SAMPLES:\n",
    "        print(f\"Skipping (n < MIN_CLUSTER_SAMPLES={MIN_CLUSTER_SAMPLES})\")\n",
    "        continue\n",
    "\n",
    "    X = sub[model_features].to_numpy()\n",
    "    y = sub[TARGET_VAR].to_numpy()\n",
    "\n",
    "    selected = run_backward_selection(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        feature_names=model_features,\n",
    "        n_features_to_select=BACKWARD_N_FEATURES_CLUSTER,\n",
    "        random_state=RANDOM_STATE,\n",
    "        scoring=SFS_SCORING,\n",
    "        cv_splits=SFS_CV_SPLITS,\n",
    "    )\n",
    "\n",
    "    r2_cl = np.nan\n",
    "    rmse_cl = np.nan\n",
    "    if selected:\n",
    "        X_sel = sub[selected].to_numpy()\n",
    "        r2_cl, rmse_cl = evaluate_selected_model(\n",
    "            X=X_sel,\n",
    "            y=y,\n",
    "            test_size=TEST_SIZE,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "\n",
    "    cluster_metrics_rows.append({\n",
    "        \"cluster\": cl,\n",
    "        \"n_cluster\": int(n_cl),\n",
    "        \"n_features\": int(len(selected)),\n",
    "        \"r2\": r2_cl,\n",
    "        \"rmse\": rmse_cl,\n",
    "    })\n",
    "\n",
    "    print(f\"Accuracy: R2={r2_cl:.4f} | RMSE={rmse_cl:.6e}\")\n",
    "    print(\"Selected features (backward order):\")\n",
    "    for i, f in enumerate(selected, 1):\n",
    "        print(f\"  {i:02d}. {f}\")\n",
    "        selected_rows.append({\n",
    "            \"cluster\": cl,\n",
    "            \"rank\": i,\n",
    "            \"feature\": f,\n",
    "            \"n_cluster\": int(n_cl),\n",
    "        })\n",
    "\n",
    "if selected_rows:\n",
    "    summary_df = pd.DataFrame(selected_rows)\n",
    "    summary_csv = SAVE_DIR / \"backward_selected_per_cluster.csv\"\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "\n",
    "    print(\"\\nSummary (backward selected features per cluster):\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    print(f\"\\n[INFO] Wrote per-cluster selection: {summary_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo clusters met MIN_CLUSTER_SAMPLES; no per-cluster results to report.\")\n",
    "\n",
    "if cluster_metrics_rows:\n",
    "    metrics_df = pd.DataFrame(cluster_metrics_rows)\n",
    "    metrics_csv = SAVE_DIR / \"backward_cluster_metrics.csv\"\n",
    "    metrics_df.to_csv(metrics_csv, index=False)\n",
    "    print(\"\\nPer-cluster model accuracy:\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "    print(f\"\\n[INFO] Wrote per-cluster metrics: {metrics_csv}\")\n",
    "\n",
    "print(f\"\\nSaved outputs to: {SAVE_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myproject)",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
