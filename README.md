
### MACHINE-LEARNING AND MODEL REDUCTION FRAMEWORK DEVELOPMENT FOR DNS DATA
Python-based open source frameworks
offer powerful platforms to assist the
construction of reduced order models
as well as for machine learning applications.
The aim of this project is to develop a
general framework that will simplify
and accelerate the application of such
tools on high-fidelity data generated by
spectral element solvers for the direct
numerical simulation (DNS) of low
Mach number reactive flows. The
framework will be used on existing
DNS data from different setups. Depending
on progress, new simulations
will also be performed for lean hydrogen-
air premixed flames to enrich the
existing datasets.

This repository contains the codebase developed as part of my Bachelor Thesis at **ETH ZÃ¼rich (D-MAVT)**, conducted in the **Computational and Applied Physics / Combustion Laboratory (CAPS)**.  
The project focuses on **data-driven modeling of hydrogen combustion** using **Direct Numerical Simulation (DNS)** data obtained from the **Nek5000** spectral-element solver.

---

## ðŸ“˜ Overview

The goal of this work is to establish a reproducible computational pipeline that:
1. Extracts local flame characteristics (e.g., curvature, strain, species concentrations) from high-fidelity DNS data.
2. Performs **feature scaling, dimensionality reduction, and regression** to uncover physical relations governing the **flame displacement speed**.
3. Bridges **physics-based modeling** with **data-driven discovery** through interpretable and efficient machine-learning models.

---

## ðŸ§© Project Structure

```text
.
â”œâ”€â”€ data/                          # Data root (NOT tracked by git)
â”‚   â”œâ”€â”€ nek/                       # Nek5000 output files
â”‚   â”‚   â”œâ”€â”€ phi0.40/
â”‚   â”‚   â”‚   â”œâ”€â”€ h400x025_ref/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ po_postPremix0.f00001
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ po_postPremix0.f00100
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ isocontours/               # Extracted flame-front CSVs
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ fields/                    # Extracted field CSVs
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ extract_isocontours/
â”‚   â”‚   â”‚   â”œâ”€â”€ extract_isocontours.ipynb
â”‚   â”‚   â”‚   â””â”€â”€ extract_isocontours.yaml
â”‚   â”‚   â””â”€â”€ extract_fields/
â”‚   â”‚       â”œâ”€â”€ extract_fields.ipynb
â”‚   â”‚       â””â”€â”€ extract_fields.yaml
â”‚   â”œâ”€â”€ case_studies/
â”‚   â”‚   â”œâ”€â”€ Model_verification/
â”‚   â”‚   â”‚   â”œâ”€â”€ Model_verification.ipynb
â”‚   â”‚   â”‚   â””â”€â”€ Model_verification.yaml
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ Archive/
â”‚
â”œâ”€â”€ flamekit/
â”‚   â”œâ”€â”€ chemical_mech/
â”‚   â”œâ”€â”€ datasets.py
â”‚   â”œâ”€â”€ io_fields.py
â”‚   â””â”€â”€ io_fronts.py
â”‚
â”œâ”€â”€ pySEMTools/                    # Local pySEMTools clone (core SEM functionality)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ report_figures/                # Generated figures (not tracked by git)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## Installation (venv)

```bash
git clone https://github.com/AlexandrosNtakoulas/Bachelor_Thesis.git
cd Bachelor_Thesis

python3 -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip

pip3 install ipython jupyter
pip3 install cantera
pip3 install pandas matplotlib scikit-learn
pip3 install seaborn
pip3 install mpi4py
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip3 install vtk
pip3 install pyvista
pip3 install pyvtk
pip3 install trame trame-vtk trame-vuetify
pip3 install pympler
pip3 install memory_profiler
pip3 install pydmd
pip3 install tables

git clone https://github.com/ExtremeFLOW/pySEMTools.git
cd pySEMTools/
pip3 install .
```

Alternative (use the requirements file):
```bash
pip3 install -r requirements.txt
```

YOU NEED TO ALSO INSTALL LATEX and the specific font type
## Usage

### 1) Place Nek5000 output files (not tracked by git)
```text
data/nek/
â””â”€â”€ phi0.40/
    â””â”€â”€ h400x025_ref/
        â”œâ”€â”€ po_postPremix0.f00001   # REQUIRED: always include the first time step
        â”œâ”€â”€ po_postPremix0.f00335   # example time step you want to analyze
        â””â”€â”€ ...
```

Notes:
- Folder structure encodes the case: `phi{PHI}/h400x{LAT_SIZE}_ref`
- File prefix depends on post-processing:
  - `POST: true` -> `po_postPremix0.fXXXXX`
  - `POST: false` -> `premix0.fXXXXX`
- Always include the first time step file (`...f00001`) in the same folder.

### 2) Extract flame fronts (HDF5)
1. Edit `notebooks/preprocessing/extract_isocontours/extract_isocontours.yaml` with your case settings.
2. Run `notebooks/preprocessing/extract_isocontours/extract_isocontours.ipynb`.

Output example:
```text
data/isocontours/
â””â”€â”€ phi0.40/
    â””â”€â”€ h400x025_ref/
        â”œâ”€â”€ extracted_flame_front_post_<TIME_STEP>_iso_<ISO>.hdf5
        â””â”€â”€ ...
```

### 3) Extract fields (HDF5)
1. Edit `notebooks/preprocessing/extract_fields/extract_fields.yaml`.
2. Run `notebooks/preprocessing/extract_fields/extract_fields.ipynb`.

Output example:
```text
data/fields/
â””â”€â”€ phi0.40/
    â””â”€â”€ h400x025_ref/
        â”œâ”€â”€ extracted_field_post_<TIME_STEP>.hdf5
        â””â”€â”€ ...
```

### 4) Run analysis notebooks
All analysis notebooks read their parameters from the YAML files in their folder under `notebooks/case_studies/`.
For example:
- `notebooks/case_studies/Sd_decomposition_analysis/Sd_decomposition_analysis.ipynb` uses `notebooks/case_studies/Sd_decomposition_analysis/Sd_decomposition_analysis.yaml`
- `notebooks/case_studies/Feature_importance_SHAP_curvature_bins/Feature_importance_SHAP_curvature_bins.ipynb` uses `notebooks/case_studies/Feature_importance_SHAP_curvature_bins/Feature_importance_SHAP_curvature_bins.yaml`

Tip: launch Jupyter from the repo root so relative paths resolve correctly.
