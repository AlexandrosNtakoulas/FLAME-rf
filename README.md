
### MACHINE-LEARNING AND MODEL REDUCTION FRAMEWORK DEVELOPMENT FOR DNS DATA
Python-based open source frameworks
offer powerful platforms to assist the
construction of reduced order models
as well as for machine learning applications.
The aim of this project is to develop a
general framework that will simplify
and accelerate the application of such
tools on high-fidelity data generated by
spectral element solvers for the direct
numerical simulation (DNS) of low
Mach number reactive flows. The
framework will be used on existing
DNS data from different setups. Depending
on progress, new simulations
will also be performed for lean hydrogen-
air premixed flames to enrich the
existing datasets.

This repository contains the codebase developed as part of my Bachelor Thesis at **ETH ZÃ¼rich (D-MAVT)**, conducted in the **Computational and Applied Physics / Combustion Laboratory (CAPS)**.  
The project focuses on **data-driven modeling of hydrogen combustion** using **Direct Numerical Simulation (DNS)** data obtained from the **Nek5000** spectral-element solver.

---

## ðŸ“˜ Overview

The goal of this work is to establish a reproducible computational pipeline that:
1. Extracts local flame characteristics (e.g., curvature, strain, species concentrations) from high-fidelity DNS data.
2. Performs **feature scaling, dimensionality reduction, and regression** to uncover physical relations governing the **flame displacement speed**.
3. Bridges **physics-based modeling** with **data-driven discovery** through interpretable and efficient machine-learning models.

---

## ðŸ§© Project Structure

```text
.
â”œâ”€â”€ data/                          # Data root (NOT tracked by git)
â”‚   â”œâ”€â”€ nek/                       # Nek5000 output files
â”‚   â”‚   â”œâ”€â”€ phi0.40/
â”‚   â”‚   â”‚   â”œâ”€â”€ h400x025_ref/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ po_postPremix0.f00001
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ po_postPremix0.f00100
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ isocontours/               # Extracted flame-front files (HDF5)
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ fields/                    # Extracted field files (HDF5, .f*)
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ extract_isocontours/
â”‚   â”‚   â”‚   â”œâ”€â”€ extract_isocontours.py
â”‚   â”‚   â”‚   â””â”€â”€ extract_isocontours.yaml
â”‚   â”‚   â””â”€â”€ extract_fields/
â”‚   â”‚       â”œâ”€â”€ extract_fields.py
â”‚   â”‚       â””â”€â”€ extract_fields.yaml
â”‚   â”œâ”€â”€ case_studies/
â”‚   â”‚   â”œâ”€â”€ Model_verification/
â”‚   â”‚   â”‚   â”œâ”€â”€ Model_verification.ipynb
â”‚   â”‚   â”‚   â””â”€â”€ Model_verification.yaml
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ Archive/
â”‚
â”œâ”€â”€ FLAME/
â”‚   â”œâ”€â”€ chemical_mech/
â”‚   â”œâ”€â”€ datasets.py
â”‚   â”œâ”€â”€ io_fields.py
â”‚   â””â”€â”€ io_fronts.py
â”‚
â”œâ”€â”€ pySEMTools/                    # Git submodule (core SEM functionality)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ report_figures/                # Generated figures (not tracked by git)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## Installation (venv)

```bash
git clone --recurse-submodules https://github.com/AlexandrosNtakoulas/Bachelor_Thesis.git
cd Bachelor_Thesis

# If you cloned earlier without --recurse-submodules:
git submodule update --init --recursive

python3 -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip

# Option 1: install from requirements file
pip install -r requirements.txt
```

`requirements.txt` installs the Python dependencies and also installs the local `pySEMTools` submodule (`-e ./pySEMTools`).

Alternative manual install:

```bash
pip3 install ipython jupyter
pip3 install cantera
pip3 install pandas matplotlib scikit-learn
pip3 install seaborn
pip3 install mpi4py
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip3 install vtk
pip3 install pyvista
pip3 install pyvtk
pip3 install trame trame-vtk trame-vuetify
pip3 install pympler
pip3 install memory_profiler
pip3 install pydmd
pip3 install tables
pip3 install tqdm
pip3 install h5py
pip3 install -e ./pySEMTools
```

## Installation on Euler HPC Cluster

```bash
git clone --recurse-submodules https://github.com/AlexandrosNtakoulas/Bachelor_Thesis.git
cd ~/Bachelor_Thesis

python -m pip install --user --upgrade virtualenv
python -m virtualenv $HOME/Bachelor_Thesis/.venv
source .venv/bin/activate

python -m ipykernel install --user --name flamekit-venv --display-name "Python (flamekit venv)"

# Continue with pip3 installation commands from this README
# For mpi4py specifically:
module load openmpi
pip install --force-reinstall mpi4py

# Link data folder from scratch to repo in home
ln -s /cluster/scratch/antakoulas/Bachelor_Thesis/data ~/Bachelor_Thesis/data
```

Tip for convenience on HPC setup:
In your `~/.bashrc` file:

```bash
alias FLAME='source "$HOME/Bachelor_Thesis/.venv/bin/activate" && export PYTHONPATH="$PWD:${PYTHONPATH}"'
```

Then to run a notebook:

```bash
salloc --ntasks=32 --cpus-per-task=1 --mem-per-cpu=20G --time=01:30:00
srun -n 8 python notebooks/preprocessing/extract_fields/extract_fields.py
```

## Updating `pySEMTools` submodule
Use this when you pull new changes from this repository and want the pinned submodule commit:

```bash
git pull
git submodule update --init --recursive
```

Use this when you want to bump `pySEMTools` to its latest upstream commit and record that update in this repository:

```bash
git submodule update --remote --recursive pySEMTools
git add pySEMTools
git commit -m "Update pySEMTools submodule"
```

YOU NEED TO ALSO INSTALL LATEX and the specific font type
## Usage

### 1) Place Nek5000 output files (not tracked by git)
```text
data/nek/
â””â”€â”€ phi0.40/
    â””â”€â”€ h400x025_ref/
        â”œâ”€â”€ po_postPremix0.f00001   # REQUIRED: always include the first time step
        â”œâ”€â”€ po_postPremix0.f00335   # example time step you want to analyze
        â””â”€â”€ ...
```

Notes:
- Folder structure encodes the case: `phi{PHI}/h400x{LAT_SIZE}_ref`
- File prefix depends on post-processing:
  - `POST: true` -> `po_postPremix0.fXXXXX`
  - `POST: false` -> `premix0.fXXXXX`
- Always include the first time step file (`...f00001`) in the same folder.

### 2) Extract flame fronts (HDF5 files)
1. Edit `notebooks/preprocessing/extract_isocontours/extract_isocontours.yaml` with your case settings.
2. Run `notebooks/preprocessing/extract_isocontours/extract_isocontours.py`.
To run using MPI: PYTHONPATH=. mpirun -n 8 python notebooks/preprocessing/extract_isocontours/extract_isocontours.py

Output example:
```text
data/isocontours/
â””â”€â”€ phi0.40/
    â””â”€â”€ h400x025_ref/
        â”œâ”€â”€ extracted_flame_front_post_<TIME_STEP>_iso_<ISO>.hdf5
        â””â”€â”€ ...
```

### 3) Extract fields (HDF5 & .f* files)
1. Edit `notebooks/preprocessing/extract_fields/extract_fields.yaml`.
2. Run `notebooks/preprocessing/extract_fields/extract_fields.py`. 
To run using MPI: PYTHONPATH=. mpirun -n 8 python notebooks/preprocessing/extract_fields/extract_fields.py


Output example:
```text
data/fields/
â””â”€â”€ phi0.40/
    â””â”€â”€ h400x025_ref/
        â”œâ”€â”€ extracted_field_post_<TIME_STEP>.hdf5
        â””â”€â”€ ...
```

### 4) Run analysis notebooks
All analysis notebooks read their parameters from the YAML files in their folder under `notebooks/case_studies/`.
For example:
- `notebooks/case_studies/FDS_decomposition_analysis/FDS_decomposition_analysis.ipynb` uses `notebooks/case_studies/FDS_decomposition_analysis/FDS_decomposition_analysis.yaml`
- `notebooks/case_studies/Feature_selection/Feature_selection.ipynb` uses `notebooks/case_studies/Feature_selection/Feature_selection.yaml`
